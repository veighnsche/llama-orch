fx:
  eur_usd_rate: 1.08

prepaid_policy:
  credits:
    min_topup_eur: 5
    max_topup_eur: 1000
    expiry_months: 12
    non_refundable: true
    auto_refill_default_enabled: false
    auto_refill_cap_eur: null
  private_tap:
    prepaid_only: true
    billing_unit_minutes: 15
    management_fee_eur_per_month: 99
    gpu_hour_markup_target_pct: 50

pricing_inputs:
  private_tap_default_markup_over_provider_cost_pct: 50
  fx_buffer_pct: 5
  effective_utilization_pct: 25
  non_gpu_overhead_multiplier_on_cost: 2

catalog:
  models_csv_path: oss_models.csv
  gpus_csv_path: gpu_rentals.csv
  price_sheet_csv_path: price_sheet.csv
  allowed_models:
    - Llama 3.1 8B
    - Llama 3.1 70B
    - Mixtral 8x7B
    - Mixtral 8x22B
    - Qwen2.5 7B
    - Qwen2.5 32B
    - Qwen2.5 72B
    - Yi-1.5 6B
    - Yi-1.5 9B
    - Yi-1.5 34B
    - DeepSeek-Coder 6.7B
    - DeepSeek-Coder 33B
    - DeepSeek-Coder-V2 16B
    - DeepSeek-Coder-V2 236B
    - Llama 3.3 70B
    - DeepSeek R1 Distill Llama 8B

payments:
  provider: stripe
  stripe:
    products:
      public_tap_credits: null
      private_tap_management_fee: null
      priority_applets: null
      oss_support: null
    webhook_endpoint_url: null
    radar_ruleset: default

tax_billing:
  vat_standard_rate_pct: 21.0
  eu_reverse_charge_enabled: true
  stripe_tax_enabled: true
  revenue_recognition: deferred_until_consumed

ops:
  rate_limits:
    public_tap:
      requests_per_minute: 60
      tokens_per_minute: 30000
    private_tap:
      requests_per_minute: null
      tokens_per_minute: null
  queue:
    policy: reject
    max_queue_depth: 128
  observability:
    enable_prometheus: true
    alert_thresholds:
      queue_depth_warn: 64
      queue_depth_crit: 120
      gpu_util_max_pct: 98
      vram_util_max_pct: 95
    retention_days:
      logs: 14
      metrics: 30
  security:
    token_required_public: true
    redact_secrets_in_logs: true

finance:
  fixed_costs_monthly_eur:
    personal: 3000
    business: null
  marketing_allocation_pct_of_inflow: 20
  runway_target_months: 6

acceptance:
  blended_gm_pct_range: [40, 60]
  max_required_inflow_eur: 12000

pricing_policy:
  version: 1
  public_tap:
    target_gross_margin_pct: 45
    min_gross_margin_pct: 25
    rounding_per_1k_tokens: 0.01
    price_floor_per_1k_tokens: 0.01
    price_cap_per_1k_tokens: null
    apply_competitor_caps: true
    optimize:
      enabled: true
      objective: profit
      elasticity_epsilon: 1.8
      reference_per_1k_tokens: null
      bounds_per_1k: null
      grid_step_per_1k: 0.005
      per_sku:
        Llama-3-1-8B:
          bounds_per_1k: [0.06, 0.09]
          elasticity_epsilon: 1.8
        Qwen2-5-7B:
          bounds_per_1k: [0.06, 0.08]
          elasticity_epsilon: 1.8
        Mixtral-8x7B:
          bounds_per_1k: [0.30, 0.50]
          elasticity_epsilon: 1.8

gpu_pricing:
  private_tap_markup_by_gpu:
    RTX 3090: 50
    RTX 4090: 50
    L4: 45
    A10: 45
    L40S: 50
    A100 40GB (PCIe): 55
    A100 80GB (SXM/PCIe): 55
    H100 80GB (PCIe/SXM): 60
    H200 141GB: 60
