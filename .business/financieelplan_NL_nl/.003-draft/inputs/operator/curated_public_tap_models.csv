Model,Variant,Developer,Capabilities,Native_Function_Calling,Context_Length_Tokens,Quantization/Runtime,Typical_VRAM_for_4bit_or_MXFP4_GB,License,Download,Benchmarks,Notes,weights_vram_4bit_gb_est,weights_vram_fp16_gb_est
GPT-OSS,20B,OpenAI,reasoning; code; structured-outputs; tool-use,yes,128000,MXFP4; vLLM; Transformers; Ollama; llama.cpp,16,Apache-2.0,openai/gpt-oss-20b,near-o3-mini (OpenAI evals),MoE total_params_b=21; active_params_b=3.6; single-GPU runnable in 16GB (MXFP4),1.68,6.71
Gemma 3,1B,Google DeepMind,reasoning; multi-modal; code; structured-outputs,no,32000,Transformers; Ollama; (experimental) llama.cpp,~4-6,Gemma License,google/gemma-3-1b-it,see model card,Gemma 3 family; 1B has 32K context; open weights with usage terms,0.47,1.86
Gemma 3,4B,Google DeepMind,reasoning; multi-modal; code; structured-outputs,no,128000,Transformers; Ollama; (experimental) llama.cpp,~8-12,Gemma License,google/gemma-3-4b-it,see model card,Multimodal; 128K context,1.86,7.45
Gemma 3,12B,Google DeepMind,reasoning; multi-modal; code; structured-outputs,no,128000,Transformers; Ollama; (experimental) llama.cpp,~20-24,Gemma License,google/gemma-3-12b-it,see model card,Multimodal; 128K context,5.59,22.35
Mistral 7B,7.3B,Mistral AI,general; code; structured-outputs,yes,8192,GGUF(Q4_K_M); llama.cpp; vLLM; Transformers,~6-8,Apache-2.0,mistralai/Mistral-7B-Instruct-v0.3,see model card,v0.3 adds function calling; tokenizer v3,3.4,13.6
CodeLlama,7B,Meta,code; infill,no,4096,GGUF(Q4_K_M); llama.cpp; vLLM; Transformers,~6-8,Meta Llama 2 Community License,meta-llama/CodeLlama-7b-hf,HumanEval≈(see card),Base Code Llama family,3.26,13.04
CodeLlama,13B,Meta,code; infill,no,4096,GGUF(Q4_K_M); llama.cpp; vLLM; Transformers,~10-12,Meta Llama 2 Community License,meta-llama/CodeLlama-13b-hf,see model card,—,6.05,24.21
CodeLlama,34B,Meta,code; infill,no,4096,GGUF(Q4_K_M); llama.cpp; vLLM; Transformers,~20-24,Meta Llama 2 Community License,meta-llama/CodeLlama-34b-hf,see model card,—,15.83,63.33
OpenCoder,1.5B,INF/Infly,code,no,4096,GGUF(4-bit); llama.cpp; Transformers,<6,INF Open Model (permissive),infly/OpenCoder-1.5B-Instruct,see model card,English/Chinese; training paper 2411.04905,0.7,2.79
OpenCoder,8B,INF/Infly,code,no,8192,GGUF(4-bit); llama.cpp; Transformers,~8-10,INF Open Model (permissive),infly/OpenCoder-8B-Instruct,see model card,English/Chinese; family includes base/chat,3.73,14.9
StarCoder2,3B,BigCode,code; infill,no,16384,GGUF; Transformers; Ollama; vLLM,~4-6,BigCode OpenRAIL-M v1,bigcode/starcoder2-3b,see model card,"SWA=4096 inside 16,384 context",1.4,5.59
StarCoder2,7B,BigCode,code; infill,no,16384,GGUF; Transformers; Ollama; vLLM,~6-8,BigCode OpenRAIL-M v1,bigcode/starcoder2-7b,see model card,"SWA=4096 inside 16,384 context",3.26,13.04
StarCoder2,15B,BigCode,code; infill,no,16384,Transformers; vLLM; (some) GGUF,~12-16,BigCode OpenRAIL-M v1,bigcode/starcoder2-15b,see model card,—,6.98,27.94
LLaMA-2 / Vicuna-type,7B,Meta/various,general; instruction-following,no,4096,GGUF(Q4_K_M); llama.cpp; vLLM; Transformers,~6-8,Llama 2 Community License,meta-llama/Llama-2-7b,see model card,Represents Vicuna/Koala-style instruct models,3.26,13.04
LLaMA-2 / Vicuna-type,13B,Meta/various,general; instruction-following,no,4096,GGUF(Q4_K_M); llama.cpp; vLLM; Transformers,~10-12,Llama 2 Community License,meta-llama/Llama-2-13b,see model card,—,6.05,24.21
