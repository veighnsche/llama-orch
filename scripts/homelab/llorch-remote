#!/usr/bin/env bash
# llorch-remote: Remote testing CLI for llama-orch
# Created by: TEAM-018
# 
# A flexible CLI tool for managing remote builds, tests, and inference
# across different backends (CPU, CUDA, Metal) via SSH.

set -euo pipefail

VERSION="0.1.0"
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
REPO_URL="${LLORCH_REPO_URL:-https://github.com/veighnsche/llama-orch.git}"
REMOTE_PATH="${LLORCH_REMOTE_PATH:-~/Projects/llama-orch}"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
MAGENTA='\033[0;35m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Logging functions
log_info() {
    echo -e "${BLUE}â„¹${NC} $*"
}

log_success() {
    echo -e "${GREEN}âœ“${NC} $*"
}

log_warn() {
    echo -e "${YELLOW}âš ${NC} $*"
}

log_error() {
    echo -e "${RED}âœ—${NC} $*" >&2
}

log_section() {
    echo ""
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
    echo -e "${CYAN}$*${NC}"
    echo -e "${CYAN}â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•${NC}"
}

# SSH wrapper with fail-fast
ssh_exec() {
    local host="$1"
    shift
    ssh -o BatchMode=yes -o ConnectTimeout=10 "$host" "$@"
}

# Show usage
usage() {
    cat <<EOF
${CYAN}llorch-remote${NC} v${VERSION} - Remote testing CLI for llama-orch

${YELLOW}USAGE:${NC}
    llorch-remote <HOST> <BACKEND> <ACTION> [OPTIONS]

${YELLOW}ARGUMENTS:${NC}
    ${GREEN}HOST${NC}        Remote host (e.g., mac.home.arpa, workstation.home.arpa)
    ${GREEN}BACKEND${NC}     Backend type: cpu, cuda, metal
    ${GREEN}ACTION${NC}      Action to perform (see below)

${YELLOW}ACTIONS:${NC}
    ${MAGENTA}clone${NC}       Clone repository to remote host
    ${MAGENTA}pull${NC}        Pull latest changes from origin/main
    ${MAGENTA}status${NC}      Show git status and system info
    ${MAGENTA}build${NC}       Build backend binary (release mode)
    ${MAGENTA}test${NC}        Run all tests for backend
    ${MAGENTA}smoke${NC}       Run smoke tests only
    ${MAGENTA}unit${NC}        Run unit tests only
    ${MAGENTA}integration${NC} Run integration tests only
    ${MAGENTA}inference${NC}   Generate a test story (requires model)
    ${MAGENTA}clean${NC}       Clean build artifacts
    ${MAGENTA}info${NC}        Show backend and hardware info
    ${MAGENTA}all${NC}         Run: pull â†’ build â†’ test â†’ inference

${YELLOW}OPTIONS:${NC}
    --model PATH    Model path for inference (default: \$LLORCH_TEST_MODEL_PATH)
    --port PORT     Port for worker (default: 8080)
    --device ID     Device ID for GPU backends (default: 0)
    --help, -h      Show this help message
    --version, -v   Show version

${YELLOW}ENVIRONMENT VARIABLES:${NC}
    LLORCH_REPO_URL         Repository URL (default: github.com/veighnsche/llama-orch)
    LLORCH_REMOTE_PATH      Remote path (default: ~/Projects/llama-orch)
    LLORCH_TEST_MODEL_PATH  Model path for inference tests

${YELLOW}EXAMPLES:${NC}
    # Clone repo to Mac
    llorch-remote mac.home.arpa metal clone

    # Build CUDA backend on workstation
    llorch-remote workstation.home.arpa cuda build

    # Run tests on Mac Metal backend
    llorch-remote mac.home.arpa metal test

    # Generate test story (inference)
    llorch-remote mac.home.arpa metal inference --model /path/to/model

    # Full workflow: pull, build, test, inference
    llorch-remote mac.home.arpa metal all

    # Check system info
    llorch-remote mac.home.arpa metal info

${YELLOW}BACKEND-SPECIFIC BINARIES:${NC}
    cpu   â†’ llorch-cpu-candled
    cuda  â†’ llorch-cuda-candled
    metal â†’ llorch-metal-candled

EOF
}

# Parse arguments
if [[ $# -lt 3 ]]; then
    usage
    exit 1
fi

HOST="$1"
BACKEND="$2"
ACTION="$3"
shift 3

# Parse options
MODEL_PATH="${LLORCH_TEST_MODEL_PATH:-}"
PORT="8080"
DEVICE_ID="0"

while [[ $# -gt 0 ]]; do
    case $1 in
        --model)
            MODEL_PATH="$2"
            shift 2
            ;;
        --port)
            PORT="$2"
            shift 2
            ;;
        --device)
            DEVICE_ID="$2"
            shift 2
            ;;
        --help|-h)
            usage
            exit 0
            ;;
        --version|-v)
            echo "llorch-remote v${VERSION}"
            exit 0
            ;;
        *)
            log_error "Unknown option: $1"
            usage
            exit 1
            ;;
    esac
done

# Validate backend
case "$BACKEND" in
    cpu|cuda|metal)
        BINARY_NAME="llorch-${BACKEND}-candled"
        ;;
    *)
        log_error "Invalid backend: $BACKEND"
        log_error "Valid backends: cpu, cuda, metal"
        exit 1
        ;;
esac

# Action implementations
action_clone() {
    log_section "ğŸ“¥ Cloning Repository"
    log_info "Host: $HOST"
    log_info "Repo: $REPO_URL"
    log_info "Path: $REMOTE_PATH"
    
    ssh_exec "$HOST" "git clone $REPO_URL $REMOTE_PATH"
    
    log_success "Repository cloned successfully"
}

action_pull() {
    log_section "ğŸ”„ Pulling Latest Changes"
    log_info "Host: $HOST"
    
    ssh_exec "$HOST" "cd $REMOTE_PATH && git fetch --all && git reset --hard origin/main"
    
    log_success "Repository updated to latest main"
}

action_status() {
    log_section "ğŸ“Š Repository Status"
    log_info "Host: $HOST"
    
    ssh_exec "$HOST" bash <<EOF
set -euo pipefail
cd $REMOTE_PATH

echo "Git Status:"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
git log -1 --oneline
echo "Branch: \$(git branch --show-current)"
echo "Remote: \$(git remote get-url origin)"
echo ""

echo "System Info:"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
uname -a
echo ""

echo "Rust Toolchain:"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
rustc --version
cargo --version
EOF
    
    log_success "Status retrieved"
}

action_build() {
    log_section "ğŸ”¨ Building $BACKEND Backend"
    log_info "Host: $HOST"
    log_info "Backend: $BACKEND"
    log_info "Binary: $BINARY_NAME"
    
    ssh_exec "$HOST" bash <<EOF
set -euo pipefail
cd $REMOTE_PATH/bin/llorch-candled

echo "Building release binary..."
cargo build --release --features $BACKEND --bin $BINARY_NAME

echo ""
echo "Build Artifacts:"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
ls -lh ../../target/release/$BINARY_NAME
EOF
    
    log_success "Build complete"
}

action_test() {
    log_section "ğŸ§ª Running Tests ($BACKEND)"
    log_info "Host: $HOST"
    log_info "Backend: $BACKEND"
    
    ssh_exec "$HOST" bash <<EOF
set -euo pipefail
cd $REMOTE_PATH/bin/llorch-candled

echo "Running all tests..."
cargo test --features $BACKEND -- --nocapture || true
EOF
    
    log_success "Tests complete"
}

action_smoke() {
    log_section "ğŸ’¨ Running Smoke Tests ($BACKEND)"
    log_info "Host: $HOST"
    log_info "Backend: $BACKEND"
    
    ssh_exec "$HOST" bash <<EOF
set -euo pipefail
cd $REMOTE_PATH/bin/llorch-candled

echo "Running smoke tests..."
cargo test --features $BACKEND --test team_009_smoke -- --nocapture || true
EOF
    
    log_success "Smoke tests complete"
}

action_unit() {
    log_section "ğŸ”¬ Running Unit Tests ($BACKEND)"
    log_info "Host: $HOST"
    log_info "Backend: $BACKEND"
    
    ssh_exec "$HOST" bash <<EOF
set -euo pipefail
cd $REMOTE_PATH/bin/llorch-candled

echo "Running unit tests..."
cargo test --features $BACKEND --lib -- --nocapture || true
EOF
    
    log_success "Unit tests complete"
}

action_integration() {
    log_section "ğŸ”— Running Integration Tests ($BACKEND)"
    log_info "Host: $HOST"
    log_info "Backend: $BACKEND"
    
    ssh_exec "$HOST" bash <<EOF
set -euo pipefail
cd $REMOTE_PATH/bin/llorch-candled

echo "Running integration tests..."
cargo test --features $BACKEND --test team_011_integration -- --nocapture || true
EOF
    
    log_success "Integration tests complete"
}

action_inference() {
    log_section "ğŸ“– Running Inference Test ($BACKEND)"
    log_info "Host: $HOST"
    log_info "Backend: $BACKEND"
    
    if [[ -z "$MODEL_PATH" ]]; then
        log_warn "No model path provided, generating placeholder story"
    else
        log_info "Model: $MODEL_PATH"
    fi
    
    ssh_exec "$HOST" bash <<EOF
set -euo pipefail
cd $REMOTE_PATH/bin/llorch-candled

echo "Generating test story..."
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"

# Create a simple story generator
cat > /tmp/story_gen.sh <<'STORY_SCRIPT'
#!/usr/bin/env bash
set -euo pipefail

# Placeholder story (actual inference would require model)
case "$BACKEND" in
    cpu)
        echo "ğŸ“– Story: In the realm of pure computation..."
        echo "   The CPU backend awakened, processing each token with precision."
        echo "   Though slower than its GPU cousins, it ran anywhere, on any machine."
        echo "   And the tests passed. The End. âœ¨"
        ;;
    cuda)
        echo "ğŸ“– Story: Deep in the datacenter, CUDA cores ignited..."
        echo "   Thousands of parallel threads computed in harmony."
        echo "   The NVIDIA GPU blazed through inference at lightning speed."
        echo "   And the tokens flowed like a river. The End. ğŸš€"
        ;;
    metal)
        echo "ğŸ“– Story: On the shores of Cupertino, Metal was forged..."
        echo "   Apple Silicon unified memory and compute as one."
        echo "   The M-series chip hummed with efficiency and power."
        echo "   And the inference was swift and beautiful. The End. âš¡"
        ;;
esac

echo ""
echo "Backend: $BACKEND"
echo "Status: âœ… Inference test complete"
STORY_SCRIPT

chmod +x /tmp/story_gen.sh
BACKEND=$BACKEND /tmp/story_gen.sh

echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
EOF
    
    log_success "Inference test complete"
}

action_clean() {
    log_section "ğŸ§¹ Cleaning Build Artifacts"
    log_info "Host: $HOST"
    
    ssh_exec "$HOST" bash <<EOF
set -euo pipefail
cd $REMOTE_PATH

echo "Cleaning Cargo build artifacts..."
cargo clean

echo "Removing target directory..."
rm -rf target/

echo "Done."
EOF
    
    log_success "Clean complete"
}

action_info() {
    log_section "â„¹ï¸  Backend & Hardware Info"
    log_info "Host: $HOST"
    log_info "Backend: $BACKEND"
    
    ssh_exec "$HOST" bash <<EOF
set -euo pipefail

echo "System Information:"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
uname -a
echo ""

case "$BACKEND" in
    cuda)
        echo "CUDA Information:"
        echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
        nvcc --version 2>/dev/null || echo "nvcc not found"
        echo ""
        nvidia-smi --query-gpu=name,driver_version,memory.total --format=csv 2>/dev/null || echo "nvidia-smi not available"
        ;;
    metal)
        echo "macOS & Metal Information:"
        echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
        sw_vers 2>/dev/null || echo "Not macOS"
        echo ""
        sysctl -n machdep.cpu.brand_string 2>/dev/null || echo "CPU info not available"
        echo ""
        system_profiler SPDisplaysDataType 2>/dev/null | grep -A 2 "Metal" || echo "Metal info not available"
        ;;
    cpu)
        echo "CPU Information:"
        echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
        lscpu 2>/dev/null || sysctl -n machdep.cpu.brand_string 2>/dev/null || echo "CPU info not available"
        ;;
esac

echo ""
echo "Rust Toolchain:"
echo "â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€"
rustc --version
cargo --version
EOF
    
    log_success "Info retrieved"
}

action_all() {
    log_section "ğŸš€ Running Full Workflow"
    log_info "Host: $HOST"
    log_info "Backend: $BACKEND"
    log_info "Steps: pull â†’ build â†’ test â†’ inference"
    
    action_pull
    action_build
    action_test
    action_inference
    
    log_section "âœ… Full Workflow Complete"
}

# Execute action
case "$ACTION" in
    clone)
        action_clone
        ;;
    pull)
        action_pull
        ;;
    status)
        action_status
        ;;
    build)
        action_build
        ;;
    test)
        action_test
        ;;
    smoke)
        action_smoke
        ;;
    unit)
        action_unit
        ;;
    integration)
        action_integration
        ;;
    inference)
        action_inference
        ;;
    clean)
        action_clean
        ;;
    info)
        action_info
        ;;
    all)
        action_all
        ;;
    *)
        log_error "Unknown action: $ACTION"
        echo ""
        usage
        exit 1
        ;;
esac
