# rbee Architecture Overview - Part 8: User Interfaces

**Version:** 1.0.0  
**Date:** October 23, 2025  
**Status:** Living Document

---

## Overview

rbee provides **multiple interfaces** for users and applications to interact with the system:

1. **rbee-keeper (CLI)** - Command-line interface for operators
2. **rbee-sdk (Library)** - Programmatic access for Rust and TypeScript
3. **rbee-web-ui (Dashboard)** - Web-based visual interface
4. **OpenAI Adapter** - Compatibility layer for OpenAI applications

**All interfaces communicate with queen-rbee via HTTP.**

---

## 1. rbee-sdk (Programmatic Interface)

### Purpose

Programmatic access to rbee infrastructure for application integration. Single-source Rust codebase that compiles to both native libraries and WASM for TypeScript.

### Architecture

```
Application (Rust/TypeScript) ‚Üí @rbee/sdk ‚Üí queen-rbee HTTP API
```

### Key Features

**Single-Source Design:**
- Rust core library
- Compiles to native (Rust apps)
- Compiles to WASM (TypeScript/JavaScript apps)
- TypeScript bindings auto-generated

**Type-Safe API:**
- Same Operation types as rbee-keeper
- Compile-time safety
- IDE auto-completion

**Cross-Platform:**
- Native: Linux, macOS, Windows
- WASM: Node.js, browsers

### API Examples

**Rust:**
```rust
use rbee_sdk::RbeeClient;

#[tokio::main]
async fn main() -> Result<()> {
    let client = RbeeClient::new("http://localhost:8500");
    
    // Spawn worker
    let mut stream = client.worker_spawn("llama-3-8b", "GPU-0").await?;
    while let Some(event) = stream.next().await {
        println!("{}", event);
    }
    
    // Run inference
    let mut stream = client.infer("Hello, world!", "llama-3-8b").await?;
    while let Some(token) = stream.next().await {
        print!("{}", token);
    }
    
    Ok(())
}
```

**TypeScript:**
```typescript
import { RbeeClient } from '@rbee/sdk';

const client = new RbeeClient('http://localhost:8500');

// Spawn worker
const stream = await client.workerSpawn('llama-3-8b', 'GPU-0');
for await (const event of stream) {
  console.log(event);
}

// Run inference
const inferStream = await client.infer('Hello, world!', 'llama-3-8b');
for await (const token of inferStream) {
  process.stdout.write(token);
}
```

### Use Cases

1. **Rust Applications** - Batch processing, custom tooling, integration tests
2. **Node.js Services** - Web servers with LLM, API gateways, background workers
3. **Browser Applications** - Interactive UIs, chat interfaces, real-time streaming
4. **Automation** - CI/CD pipelines, testing frameworks, monitoring tools

### Status

- **Location:** `consumers/rbee-sdk/`
- **Version:** 0.0.0 (design phase)
- **Implementation:** Stubs only (methods unimplemented)
- **Effort:** 22-32 hours to complete

---

## 2. rbee-web-ui (Web Dashboard)

### Purpose

**Management dashboard** for rbee infrastructure - catalog, deployments, monitoring.

**NOT for chat/inference** - for that, you connect directly to workers.

### The rbee Pattern: Direct-to-Worker

**How rbee is different:**

```
Traditional (centralized):
  Browser ‚Üí Dashboard ‚Üí Queen ‚Üí Worker
             (all inference through dashboard)

rbee (direct-to-worker):
  Browser ‚Üí Dashboard ‚Üí Queen (management only)
  Browser ‚Üí Worker (direct chat/inference)
          (connect directly to worker's frontend)
```

**Why direct-to-worker?**
- ‚úÖ **Lower latency** - No proxy overhead
- ‚úÖ **Specialized UIs** - Each worker type has optimized frontend
- ‚úÖ **ComfyUI pattern** - Same approach as ComfyUI (workers serve their own UI)
- ‚úÖ **Scalability** - Queen not bottleneck for inference traffic

### Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  rbee-web-ui (Management Dashboard)                     ‚îÇ
‚îÇ  http://localhost:3002                                  ‚îÇ
‚îÇ  ‚îú‚îÄ Model Catalog (browse, filter, compatibility)      ‚îÇ
‚îÇ  ‚îú‚îÄ Deployments (spawn workers, manage replicas)       ‚îÇ
‚îÇ  ‚îú‚îÄ Monitoring (GPU usage, metrics)                    ‚îÇ
‚îÇ  ‚îî‚îÄ [Open Chat] button ‚Üí redirects to worker URL       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚Üì Management operations only
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  queen-rbee (http://localhost:8500)                     ‚îÇ
‚îÇ  ‚îú‚îÄ Worker lifecycle (spawn, stop)                     ‚îÇ
‚îÇ  ‚îú‚îÄ Model management (download, delete)                ‚îÇ
‚îÇ  ‚îî‚îÄ Health/status                                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

         Inference happens directly:
         
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Browser connects DIRECTLY to worker                    ‚îÇ
‚îÇ  http://localhost:9001 (worker-1: llama-3-8b)          ‚îÇ
‚îÇ  ‚îú‚îÄ Chat interface (specialized for LLM)               ‚îÇ
‚îÇ  ‚îú‚îÄ Parameter controls (temp, top_p, max_tokens)       ‚îÇ
‚îÇ  ‚îî‚îÄ Streaming output (token-by-token)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Browser connects DIRECTLY to ComfyUI worker           ‚îÇ
‚îÇ  http://localhost:9002 (worker-2: stable-diffusion)    ‚îÇ
‚îÇ  ‚îú‚îÄ ComfyUI workflow editor (native ComfyUI UI)       ‚îÇ
‚îÇ  ‚îú‚îÄ Node graph                                         ‚îÇ
‚îÇ  ‚îî‚îÄ Image gallery                                      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Key Features

**1. Hive Catalog (Model Repository)**

**Purpose:** Browse and spawn workers with models

**Features:**
- Model cards with metadata (size, format, architecture)
- **Hive compatibility checks** (VRAM requirements vs available cells)
- Filter by: size, format (GGUF, safetensors), architecture
- Search by name/description
- **Spawn Worker** button ‚Üí deploys to hive

**UI Example:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üêù Qwen3-0.5B                    [Spawn Worker ‚ñº]   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Model: Qwen/Qwen2.5-0.5B-Instruct                    ‚îÇ
‚îÇ Format: GGUF (Q4_K_M)   Size: 352 MB                 ‚îÇ
‚îÇ Context: 32K tokens     Layers: 24                   ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ üü¢ Hive Ready                                        ‚îÇ
‚îÇ    VRAM needed: ~680 MB per worker                   ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ Available Cells (GPUs):                              ‚îÇ
‚îÇ   ‚Ä¢ Cell-0 (cuda:0, RTX 4090) - 22.4GB free ‚úÖ      ‚îÇ
‚îÇ   ‚Ä¢ Cell-1 (cuda:1, RTX 3090) - 18.2GB free ‚úÖ      ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ [Text Generation] [Fast Inference] [Apache 2.0]     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Spawn Worker Modal:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Spawn Worker: Qwen3-0.5B                    [√ó]      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Worker ID                                             ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ
‚îÇ ‚îÇ qwen3-worker-1 ‚úèÔ∏è             ‚îÇ                   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ Worker Type                                          ‚îÇ
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                   ‚îÇ
‚îÇ ‚îÇ llm-worker-rbee (Candle) ‚ñº   ‚îÇ                   ‚îÇ
‚îÇ ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                   ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ Assign to Cell: cuda:0 (Cell-0) ‚ñº                   ‚îÇ
‚îÇ Quantization: Q4_K_M ‚ñº                               ‚îÇ
‚îÇ Swarm Size: 1 worker (click for multi-worker)       ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ üîß Advanced (temperature, context, etc.)            ‚îÇ
‚îÇ                                                       ‚îÇ
‚îÇ           [Cancel]  [Spawn]                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**2. Worker Pool (Active Workers)**

**Purpose:** Manage active workers in the hive

**Features:**
- List all workers across hives
- Status indicators (üü¢ active, üü° spawning, üî¥ failed, ‚ö´ idle)
- **Swarm** - Multiple workers of same model (load distribution)
- **[Connect ‚Üí]** button - Opens worker's direct interface
- Stop/restart workers
- View worker logs
- Cell assignment (which GPU)

**UI Example:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üêù Worker Pool                              [Spawn Worker ‚ñº]    [‚Üª Refresh]  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ [Search workers...] [Filter by hive ‚ñº] [Filter by status ‚ñº]  [‚Üª]            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  ‚úì   ‚îÇ Worker              ‚îÇ Model              ‚îÇ Cell     ‚îÇ Spawned      ‚îÇ ‚öôÔ∏è‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  √ó   ‚îÇ qwen3-worker-1      ‚îÇ Qwen3-0.5B        ‚îÇ Cell-0   ‚îÇ 2025-07-16   ‚îÇ üóëÔ∏è‚îÇ
‚îÇ      ‚îÇ üü¢ Active           ‚îÇ (GGUF Q4_K_M)     ‚îÇ cuda:0   ‚îÇ 16:27:15     ‚îÇ   ‚îÇ
‚îÇ      ‚îÇ [Connect ‚Üí]         ‚îÇ Swarm: 1/1        ‚îÇ          ‚îÇ              ‚îÇ   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  √ó   ‚îÇ llama3-worker-2     ‚îÇ Llama-3.1-8B      ‚îÇ Cell-1   ‚îÇ 2025-07-16   ‚îÇ üóëÔ∏è‚îÇ
‚îÇ      ‚îÇ ‚ö´ Idle (5m)        ‚îÇ (GGUF Q5_K_M)     ‚îÇ cuda:1   ‚îÇ 15:42:08     ‚îÇ   ‚îÇ
‚îÇ      ‚îÇ [Connect ‚Üí]         ‚îÇ Swarm: 1/1        ‚îÇ          ‚îÇ              ‚îÇ   ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ  √ó   ‚îÇ sd-worker-3         ‚îÇ SDXL-1.0          ‚îÇ Cell-0   ‚îÇ 2025-07-16   ‚îÇ üóëÔ∏è‚îÇ
‚îÇ      ‚îÇ üü° Spawning...      ‚îÇ (safetensors)     ‚îÇ cuda:0   ‚îÇ 16:55:33     ‚îÇ   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Terminology:**
- **Worker Pool** - All active workers (instead of "deployments")
- **Swarm** - Multiple workers of same model (instead of "replicas")
- **Cell** - GPU/compute unit (instead of "backend" or "GPU")
- **Connect** - Open worker interface (instead of "Open Chat")
- **Spawn** - Create worker (instead of "Deploy")

**Click [Connect ‚Üí] ‚Üí Opens worker's direct interface:**
- For LLM workers: `http://localhost:9001` (chat interface)
- For ComfyUI: `http://localhost:9002` (workflow editor)
- For Stable Diffusion: `http://localhost:9003` (generation interface)

**3. Worker Interface (Direct Connection)**

**Purpose:** Connect directly to worker's specialized interface

**URL:** `http://localhost:9001` (worker's own HTTP server)

**Features:**
- Direct worker connection (zero proxy overhead)
- Streaming output (token-by-token)
- Worker-specific controls
- Real-time metrics
- Session history

**Worker Interface Elements:**
- **Worker ID** - Identifies this worker instance
- **Cell Assignment** - Which GPU this worker uses
- **Model Info** - Model name, size, quantization
- **Control Panel** - Temperature, tokens, sampling params
- **Conversation** - Message history with streaming
- **Metrics** - Token count, generation speed, VRAM usage

**UI Example:**
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ üêù Worker: qwen3-worker-1                        [Metrics]  [Settings]  [‚öôÔ∏è]  ‚îÇ
‚îÇ Cell-0 (cuda:0) ‚Ä¢ Model: Qwen3-0.5B (Q4_K_M) ‚Ä¢ VRAM: 680 MB / 24 GB          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                     ‚îÇ  üéõÔ∏è Controls                            ‚îÇ
‚îÇ üë§ You                             ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ tell me a joke                     ‚îÇ  ‚îÇ Worker: qwen3-worker-1            ‚îÇ  ‚îÇ
‚îÇ                                     ‚îÇ  ‚îÇ Cell: Cell-0 (cuda:0)             ‚îÇ  ‚îÇ
‚îÇ üêù Worker Response                 ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ [streaming tokens...]              ‚îÇ                                         ‚îÇ
‚îÇ Okay, here's a light one:          ‚îÇ  Temperature: ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  0.9        ‚îÇ
‚îÇ Why did the bee go to therapy?     ‚îÇ  Max Tokens:  ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  4096       ‚îÇ
‚îÇ Because it had too many...          ‚îÇ  Top P:       ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  0.95       ‚îÇ
‚îÇ                                     ‚îÇ  Top K:       ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  40         ‚îÇ
‚îÇ                                     ‚îÇ  Repeat Penalty: ‚óè‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  1.1        ‚îÇ
‚îÇ üìä Tokens: 45 generated            ‚îÇ  Seed: [865]  [üé≤ Random]               ‚îÇ
‚îÇ ‚ö° Speed: 32.5 tok/s               ‚îÇ                                         ‚îÇ
‚îÇ                            [üìã Copy]‚îÇ  [Stop Generation]                      ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§                                         ‚îÇ
‚îÇ ‚îÇ Message this worker...          ‚îÇ                                         ‚îÇ
‚îÇ ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ[üêù]‚îÇ                                         ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Key Features:**
- **Direct connection** - Worker serves its own UI (no proxy)
- **Cell visibility** - Shows which GPU worker uses
- **Streaming** - Token-by-token generation
- **Real-time metrics** - Token count, speed, VRAM
- **Worker identity** - Clear worker ID and cell assignment
- **Specialized** - UI optimized for worker type (LLM, image gen, etc.)

### Tech Stack

- **Next.js 15** - React framework with App Router
- **React 19** - UI library
- **TypeScript** - Type safety
- **@rbee/sdk** - WASM-compiled TypeScript client
- **@rbee/ui** - Shared component library (shadcn/ui)
- **Tailwind CSS** - Styling
- **SSE** - Server-Sent Events for streaming

### Project Structure (Management Dashboard)

```
rbee-web-ui/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ app/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ layout.tsx          # Root layout
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ page.tsx            # Hive overview
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ catalog/            # Hive catalog (models)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx        # Browse models, spawn workers
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ workers/            # Worker pool (active workers)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx        # List workers, [Connect] buttons
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cells/              # Cell monitoring (GPU status)
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ page.tsx        # Cell usage, VRAM, temperature
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hives/              # Hive management
‚îÇ   ‚îÇ       ‚îî‚îÄ‚îÄ page.tsx        # Install, start, stop hives
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model-card.tsx      # Model card in catalog
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ spawn-modal.tsx     # Spawn worker dialog
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ worker-list.tsx     # Active workers list
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ cell-status.tsx     # Cell (GPU) status card
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ swarm-indicator.tsx # Swarm size display
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ cell-graphs.tsx     # Cell usage graphs
‚îÇ   ‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ use-rbee-client.ts  # SDK client hook
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ use-catalog.ts      # Model catalog data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ use-workers.ts      # Active workers data
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ use-cells.ts        # Cell (GPU) metrics
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ use-hives.ts        # Hive status
‚îÇ   ‚îî‚îÄ‚îÄ lib/
‚îÇ       ‚îî‚îÄ‚îÄ rbee.ts             # SDK configuration
‚îî‚îÄ‚îÄ package.json
```

### Worker Frontends (Separate from Dashboard)

**Each worker serves its own specialized frontend:**

```
bin/30_llm_worker_rbee/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.rs                 # Worker HTTP server
‚îÇ   ‚îú‚îÄ‚îÄ inference.rs            # LLM inference
‚îÇ   ‚îî‚îÄ‚îÄ frontend/               # Worker's own UI
‚îÇ       ‚îú‚îÄ‚îÄ chat.html           # Chat interface (served at /)
‚îÇ       ‚îú‚îÄ‚îÄ chat.js             # Client-side logic
‚îÇ       ‚îî‚îÄ‚îÄ chat.css            # Styling
‚îî‚îÄ‚îÄ Cargo.toml
```

**Worker HTTP Server (serves UI):**
```rust
// bin/30_llm_worker_rbee/src/main.rs
use axum::{Router, routing::{get, post}};

#[tokio::main]
async fn main() {
    let app = Router::new()
        // Serve chat UI at root
        .route("/", get(serve_chat_ui))
        
        // API endpoints
        .route("/v1/infer", post(handle_infer))
        .route("/v1/status", get(handle_status));
    
    // Worker listens on its own port
    let addr = format!("0.0.0.0:{}", port);
    axum::Server::bind(&addr.parse()?)
        .serve(app.into_make_service())
        .await?;
}

async fn serve_chat_ui() -> Html<&'static str> {
    Html(include_str!("frontend/chat.html"))
}
```

**Worker Chat UI (chat.html):**
```html
<!DOCTYPE html>
<html>
<head>
  <title>üêù rbee Worker - {model_name}</title>
  <style>/* GPUStack-inspired styling */</style>
</head>
<body>
  <div class="chat-container">
    <div class="messages" id="messages"></div>
    <div class="input-area">
      <textarea id="prompt"></textarea>
      <button onclick="sendMessage()">Send</button>
    </div>
  </div>
  
  <div class="params-sidebar">
    <h3>Parameters</h3>
    <label>Temperature: <input type="range" id="temp" /></label>
    <label>Max Tokens: <input type="range" id="max_tokens" /></label>
    <!-- More parameters -->
  </div>
  
  <script>
    // Direct connection to THIS worker
    async function sendMessage() {
      const prompt = document.getElementById('prompt').value;
      const response = await fetch('/v1/infer', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'},
        body: JSON.stringify({prompt, temperature: 0.9, max_tokens: 4096})
      });
      
      // Stream tokens
      const reader = response.body.getReader();
      while (true) {
        const {done, value} = await reader.read();
        if (done) break;
        displayToken(new TextDecoder().decode(value));
      }
    }
  </script>
</body>
</html>
```

### ComfyUI Worker (Native UI)

**ComfyUI already has its own UI:**

```
bin/35_adapters/rbee-comfyui-adapter/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.rs                 # Adapter
‚îÇ   ‚îî‚îÄ‚îÄ comfyui_subprocess.rs   # Spawn ComfyUI
‚îî‚îÄ‚îÄ Cargo.toml
```

**ComfyUI serves its native UI at its port:**
```rust
// Adapter just spawns ComfyUI, doesn't need to serve UI
let comfyui = Command::new("python")
    .arg("-m").arg("comfyui")
    .arg("--port").arg("9002")
    .spawn()?;

// ComfyUI serves its own UI at http://localhost:9002
// Dashboard [Open Chat] button links to it directly
```

### Implementation Workflow

**1. User spawns worker from catalog:**
```
Dashboard: Catalog ‚Üí Select model ‚Üí [Spawn Worker]
  ‚Üì
Spawn modal: Choose cell (GPU), swarm size, worker type
  ‚Üì
Dashboard sends: POST /v1/jobs (Operation::WorkerSpawn)
  ‚Üì
Queen routes to appropriate Hive
  ‚Üì
Hive spawns worker on assigned cell (port 9001)
  ‚Üì
Worker starts HTTP server with embedded interface
  ‚Üì
Dashboard updates: Worker Pool shows "qwen3-worker-1 üü¢ Active"
```

**2. User connects to worker:**
```
Dashboard: Worker Pool ‚Üí [Connect ‚Üí] button
  ‚Üì
Opens new tab: http://localhost:9001
  ‚Üì
Browser connects DIRECTLY to worker (zero proxy)
  ‚Üì
Worker serves its specialized interface
  ‚Üì
User interacts directly with worker
  (LLM chat, ComfyUI workflows, image generation, etc.)
```

### Status

**Management Dashboard:**
- **Location:** `frontend/apps/rbee-web-ui/`
- **Version:** 0.1.0 (stub)
- **Runs on:** `http://localhost:3002`
- **Dependencies:** Requires `@rbee/sdk` implementation
- **Effort:** 44-60 hours (after SDK ready)

**Worker Frontends:**
- **LLM Worker:** `bin/30_llm_worker_rbee/src/frontend/`
- **Status:** Not implemented (M1/M2)
- **Effort:** 16-24 hours per worker type
- **ComfyUI:** Uses native ComfyUI UI (no additional work)

---

## 3. OpenAI API Adapter

### Purpose

OpenAI-compatible HTTP API that translates OpenAI requests to rbee Operations. Enables existing OpenAI applications to work with rbee without modification.

### Architecture

```
OpenAI SDK (Python/JS/Rust) ‚Üí /openai/v1/* ‚Üí OpenAI Adapter ‚Üí rbee Operations ‚Üí queen-rbee
```

### Supported Endpoints

**POST /openai/v1/chat/completions**
- Chat completions (streaming and non-streaming)
- Converts messages array to single prompt
- Maps OpenAI parameters to rbee parameters

**GET /openai/v1/models**
- List available models in OpenAI format

**GET /openai/v1/models/{model}**
- Get model details

### Request Translation

**OpenAI Request:**
```json
{
  "model": "llama-3-8b",
  "messages": [
    {"role": "system", "content": "You are helpful."},
    {"role": "user", "content": "Hello!"}
  ],
  "temperature": 0.7,
  "max_tokens": 100,
  "stream": true
}
```

**Translated to rbee:**
```rust
Operation::Infer {
    prompt: "<|system|>\nYou are helpful.\n</|system|>\n\n
