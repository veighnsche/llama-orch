# Workflow

## 0) Guiding Principles

1. **Spec is law.** Requirements live in a single SPEC with stable IDs (`ORCH-XXXX`). All artifacts reference these IDs.
2. **Contract‑first.** OpenAPI + config schema + metrics are versioned contracts; code is generated/validated against them.
3. **TDD.** Write tests first: contracts → CDC (Pact) → stubs → provider verify → properties → E2E.
4. **Determinism by default.** Within a replica set, same `{prompt, params, seed}` MUST yield identical tokens.
5. **Fail fast.** No CPU spill; typed errors + backpressure.
6. **Short sessions.** No long‑running chats; no KV migration.
7. **Real‑model proof.** A live NVIDIA GPU Worker MUST pass the **Haiku** E2E test; prefer hitting a GPU worker over LAN from the dev box runner. In CI where a GPU is unreachable, allow a clearly marked CI‑only CPU carve‑out (still a real model). Mocks cannot satisfy release gates.

---

## 1) Repository Layout (workspace)

```bash
/ Cargo.toml                       # [workspace]
/.specs/
  orchestrator-spec.md             # RFC‑2119 with ORCH‑IDs
  metrics/otel-prom.md             # metric names, labels, units
/contracts/
  openapi/
    control.yaml                   # Control plane API (OpenAPI‑first)
    data.yaml                      # Data plane API (OpenAPI‑first)
  schemas/
    (emitted) config.schema.json   # From Rust types via schemars
  pacts/
    *.json                         # Consumer Pact files (in‑repo, no broker)
/contracts/api-types/              # Rust types generated by oapi‑codegen
/contracts/config-schema/          # Rust config types (emit JSON Schema)
/orchestrator-core/                # lib: queues, placement, fairness, SLO
/orchestratord/                    # bin: controller API (Axum/Tokio)
/pool-managerd/                    # bin: per‑host agent (spawns Workers by engine)
/worker-adapters/
  llamacpp-http/                   # lib: WorkerAdapter over llama.cpp HTTP
  vllm-http/                       # lib: WorkerAdapter over vLLM (OpenAI‑compat)
  tgi-http/                        # lib: WorkerAdapter over HF TGI
  triton/                          # lib: WorkerAdapter over Triton/TensorRT‑LLM
  mock/                            # lib: fault‑injecting adapter
/plugins/
  policy-host/                     # lib: WASI plugin loader/bridge
  policy-sdk/                      # lib: SDK for WASI placement policies
/cli/consumer-tests/               # Pact tests & CLI snapshots (insta)
/test-harness/
  e2e-haiku/                       # REAL MODEL haiku test (blocking)
  determinism-suite/               # 2 replicas, byte‑exact match
  chaos/                           # kill/restart/drain/reset scenarios (nightly)
/tools/
  spec-extract/                    # SPEC.md → requirements/*.yaml (per-spec requirement files)
  openapi-client/                  # generated client for black‑box tests
/requirements/
  *.yaml                           # AUTO‑GEN per spec: req → tests → code (e.g., 00_llama-orch.yaml)
/ci/
  pipelines.yml                    # CI jobs
  dashboards/                      # Grafana dashboards & alerts
COMPLIANCE.md                      # AUTO‑GEN: req coverage
CHANGELOG_SPEC.md                  # Spec deltas
PROJECT_GUIDE.md                   # Newcomer on‑ramp

---

## Product Plan (Epics, MVP, Journeys)

This section makes the PRODUCT explicit: what we are shipping, for whom, and how it maps to stages/specs.

### Personas

- Platform Engineer (runs orchestrator + workers; needs reliability, metrics, knobs)
- ML Engineer (submits prompts; needs deterministic streams, cancel, budgets)
- SRE (cares about SLOs, dashboards, alerts; anti‑cheat integrity)

### MVP Definition (what v0.1 must ship)

- Single‑tenant orchestrator exposing OrchQueue v1 APIs:
  - `POST /v1/tasks`, `GET /v1/tasks/:id/stream`, `POST /v1/tasks/:id/cancel`
  - Minimal sessions: `GET/DELETE /v1/sessions/:id`
- One real engine (llama.cpp) via adapter, deterministic SSE (`started|token|metrics|end|error`)
- Admission (bounded queue) + basic placement to one ready replica
- Core metrics per `.specs/metrics/otel-prom.md` + `/metrics` endpoint + dashboards
- CLI quickstart + Haiku anti‑cheat E2E passing on a real worker

### User Journeys (end‑to‑end)

1) Submit → Stream → Cancel
   - Create a task, stream tokens deterministically, cancel on demand; observe tokens/latency metrics
2) Scale a pool
   - Start pool‑managerd for llama.cpp, see replicas Ready, submit tasks, drain/reload without downtime
3) Observe & debug
   - Watch Grafana panels (queue_depth, rejections, latencies, tokens); enforce budgets; check logs
   See also:
   - `.plan/72_bdd_harness.md` (journeys)
   - `.plan/73_e2e_haiku.md` (anti‑cheat E2E)
   - `.plan/80_cli.md` (CLI UX)
   - `.plan/90_tools.md` (tools and xtask)

### Epics (map to stages)

- Epic A — Admission & Dispatch (Stage 6)
  - Queue → scheduler/placement → adapter submit; readiness gating; version pinning; engine flags
- Epic B — Pool Manager (Stage 7)
  - Replica registry, heartbeats, drain/reload, leases; propagate `engine_version`/`model_digest`
- Epic C — Adapters (Stage 8)
  - llama.cpp first; then vLLM, TGI, Triton; SSE, backpressure, errors; metrics adherence
- Epic D — Scheduling & Fairness (Stage 9)
  - Priority fairness; `admission_share`, `deadlines_met_ratio` gauges; tests
- Epic E — Capabilities (Stage 10)
  - `GET /v1/replicasets` or `/v1/capabilities`; provider verify + snapshots
- Epic F — Config & Quotas (Stage 11)
  - Engine/worker examples; quotas; env conventions
- Epic G — BDD Coverage (Stage 12)
  - Feature tests for journeys; no undefined/ambiguous steps
- Epic H — Observability Dashboards (Stage 13)
  - Grafana panels + alert budgets; CI render checks
- Epic I — Startup Self‑Tests (Stage 14)
  - Preload, minimal decode, cancel, telemetry
- Epic J — Real‑Model E2E (Stage 15)
  - Haiku anti‑cheat; metrics delta; ≤ 30 s
- Epic K — Chaos & Load (Stage 16)
- Epic L — Compliance & Release (Stage 17)

Each Epic has acceptance criteria in the Stage Flow below; link test artifacts in `.docs/DONE/` per milestone.

---

## 2) Locked‑In Choices (rationale)

* **OpenAPI:** **OpenAPI‑first** with `oapi-codegen` (true contract‑first; language‑agnostic; CI diffable).
* **Config schema:** **Rust types → JSON Schema** via `schemars` (DRY validation; compile‑time guarantees).
* **CDC:** **Pact (file‑based)** in repo (simple, reviewable; broker optional later).
* **Stubs:** **wiremock‑rs** (fast/ergonomic), backed by pact expectations.
* **Snapshots:** **insta** (diff‑friendly CLI transcripts/JSON/logs).
* **Properties:** **proptest** (invariants for queues/fairness/idempotency).
* **Determinism defaults:** inject `seed = hash(job_id)` if omitted; pin `sampler_profile_version = "v1"`.
* **Real model for CI:** **Qwen2.5‑0.5B‑Instruct (GGUF, Q4\_K\_M)** as **default**; **TinyLlama‑1.1B‑Chat (Q4\_K\_M)** as **fallback**; optional **SmolLM2‑1.7B‑Instruct** on nightly. Prefer targeting a GPU worker over LAN; if unavailable in CI, fall back to CPU locally.
* **Replica determinism flags (per engine):** for llama.cpp run with **`--parallel 1`** and **`--no-cont-batching`**; for other engines, use single‑slot/single‑request mode or their documented equivalents to ensure byte‑exact tests; pin engine commit/version.
* **Observability:** Prometheus + Grafana; JSON logs via `tracing`. Cardinality guards on labels. Metrics MUST include `engine` and engine‑specific version labels (e.g., `engine_version`, `trtllm_version`). See `.specs/metrics/otel-prom.md`.
* **Auth:** API key (HMAC) day‑1; OIDC later. Quotas: concurrent jobs, tokens/min, KV‑MB.
* **Policy plugins:** WASI (Rust first), pure deterministic function over snapshot, ≤ **1 ms** budget.
* **CI:** Prefer a dev‑hosted NVIDIA GPU worker reachable over LAN from the runner. If cloud CI cannot reach a GPU, add a clearly marked CI‑only CPU carve‑out (temporary); production remains NVIDIA‑only.

---

## 3) Stage Flow (TDD)

Note on heterogeneous GPUs: cross‑GPU splits are opt‑in and require explicit per‑GPU ratios; default is no cross‑GPU split. See the config example in `.specs/orchestrator-spec.md` §8.

### Stage 0 — Contract Freeze (TDD seed)

1. Author `contracts/openapi/{data.yaml,control.yaml}` with `x-req-id: ORCH-…` links back to SPEC. Define the public orchestrator API as **OrchQueue v1**: tasks, sessions, streams. Include an explicit `engine` enum on all relevant resources/types: `llamacpp | vllm | tgi | triton` (applies to Task, Pool, and typed error envelopes where relevant).
2. Generate Rust server/client with `oapi-codegen` into `/contracts/api-types` + server stubs in `/orchestratord`.
3. Define Rust config types in `/contracts/config-schema` (include `engine`, `devices`, optional `tensor_split` ratios) and **emit** `config.schema.json` via `schemars`.
   **Gate:** CI fails if OpenAPI or schema regeneration yields diffs.

### Stage 1 — Consumer‑Driven Tests (CLI) + Snapshots

1. Write **Pact** tests in `/cli/consumer-tests` against **OrchQueue v1** endpoints: `POST /v1/tasks`, `GET /v1/tasks/:id/stream`, `POST /v1/tasks/:id/cancel`, session endpoints. Commit pact JSON under `/contracts/pacts/`.
2. Run CLI against **wiremock‑rs** stubs that satisfy the pact. Capture CLI transcripts and JSON with **insta** snapshots.
   **Gate:** Pact tests + snapshots green before provider coding.

### Stage 2 — Provider Verification (orchestrator)

1. Add **Pact provider verification** (orchestratord) that loads pact files and verifies real handlers.
2. Implement minimal vertical slice to pass: admission → placement to one ready replica; determinism plumbing; fail‑fast errors + backpressure. Ensure all typed errors conform to contract and carry engine context where applicable.
   **Gate:** Provider verification green.

### Stage 3 — Properties & Invariants (core)

1. In `orchestrator-core`, add **proptest** suites for: FIFO invariants; priority fairness; `reject` vs `drop-lru` semantics; race‑free cancel.
   **Gate:** Property suites green.

### Stage 4 — Determinism Suite (replica set)

1. Launch two identical replicas per engine (same `engine_version` & sampler profile). For llama.cpp, start with **`--parallel 1 --no-cont-batching`**; for other engines, use single‑slot or documented equivalents to disable cross‑request batching.
2. Run **64 seeded prompts**; assert first‑32 tokens and full streams are **byte‑exact** for each engine.
    **Gate:** Any divergence → CI red with token diff artifact.

### Stage 5 — Observability & SLOs

1. Implement metrics exactly per `.specs/metrics/otel-prom.md` (names, units, labels). Labels MUST include `engine` and engine‑specific version labels (e.g., `engine_version`, `trtllm_version`). Add JSON logs with required fields (incl. `engine`, `seed`, `engine_version`, `sampler_profile_version`).
2. Commit Grafana dashboards + alert rules under `/ci/dashboards`.
    **Gate:** Metrics linter + dashboard render pass in CI (sample data).

### Stage 6 — Admission → Dispatch vertical (product)

1. Deliverables:
   - `POST /v1/tasks` enqueues via core queue (`QueueWithMetrics`) and returns 202 with `task_id`, `correlation_id`.
   - Placement selects a single Ready replica; `GET /v1/tasks/:id/stream` streams SSE (`started|token|metrics|end|error`).
   - `POST /v1/tasks/:id/cancel` cancels queued/active tasks; determinism flags per engine; readiness gating.
   **Gate:** Provider verify green for POST/GET/cancel; SSE events well-formed; metrics side-effects observed.

### Stage 7 — Pool manager readiness

1. Deliverables:
   - Replica registry (heartbeat/health/readiness), drain/reload, leases; surface `engine_version`/`model_digest`.
   - Control-plane: `POST /v1/pools/:id/{drain,reload}`, `GET /v1/pools/:id/health`, `GET /v1/replicasets`.
   **Gate:** Only Ready replicas advertised; pin `engine_version` and `sampler_profile_version`; do not mix.

### Stage 8 — Worker adapters conformance

1. Deliverables:
   - Adapters: mock, llamacpp-http, vllm-http, tgi-http, triton. SSE framing/backpressure/timeouts/typed errors.
   - Metrics emission per contract: tokens in/out, latencies, labels {engine,engine_version,pool_id,replica_id,priority}.
   **Gate:** Adapter integration tests pass; determinism normalization per engine; version labels present.

### Stage 9 — Scheduling & fairness

1. Deliverables:
   - Finalize policy; wire `admission_share` and `deadlines_met_ratio`; tune backpressure.
   **Gate:** Fairness property unignored and green; end-to-end fairness behavior validated.

### Stage 10 — Capability discovery

1. Deliverables:
   - `GET /v1/replicasets` or `GET /v1/capabilities` with API version, `ctx_max`, features, limits; snapshots + provider verify.

### Stage 11 — Config & quotas

1. Deliverables:
   - Engine/worker examples; quotas (concurrent jobs, tokens/min, KV-MB); env conventions enforced.

### Stage 12 — BDD coverage (journeys)

1. Deliverables:
   - Features for admission, cancel, backpressure, fairness bounds, determinism toggles; zero undefined/ambiguous.

### Stage 13 — Dashboards & alerts

1. Deliverables:
   - Panels (queue_depth, rejections, latencies, tokens) + alert budgets in `/ci/dashboards`; CI render check.

### Stage 14 — Startup self-tests

1. Deliverables:
   - Preload, minimal decode, cancel, telemetry; fail fast on violation.

### Stage 15 — Real-Model E2E (Haiku) — anti-cheat gate

1. Deliverables:
   - E2E test in `test-harness/e2e-haiku/` driving only OrchQueue v1; minute+nonce; metrics token delta > 0; engine/model visible.
   **Gate:** Pass within time budget; anti-cheat enforced (real Worker, no fixtures, repo scan, REQUIRE_REAL_LLAMA=1).

### Stage 16 — Chaos & Load (nightly)

1. Deliverables:
   - `test-harness/chaos/` scenarios (kill/restart/drain/reset) and short load SLO checks.
   **Gate:** Nightly-only pass.

### Stage 17 — Compliance & Release

1. Deliverables:
   - `tools/spec-extract` → `requirements/*.yaml` refreshed; `COMPLIANCE.md` generated; `CHANGELOG_SPEC.md` updated; artifacts published.
   **Gate:** Spec-extract diff-clean; linkcheck green; workspace fmt/lint/tests green.

---

## 4) Haiku Test (Normative Protocol)

**Inputs**

* `minute_words` = current minute in English (Europe/Amsterdam): "zero".."fifty‑nine".
* `nonce` = 8‑char random token.
* `seed` = fixed (or injected from `job_id`).

**Prompt template**

> Write a haiku (3 lines). Include this exact English minute phrase: "\<minute\_words>". Also include this nonce verbatim: "<nonce>". Output only the poem.

**Accept if**

* Output has ≥ 3 non‑empty lines.
* Contains `minute_words` and `nonce`.
* `/metrics` token counter increased (read once before job, once after).
* Worker exposes `engine_version` and `model_digest` (metrics or models API).

**Anti‑cheat**

* Fail if mock/stub engine detected or `/metrics` absent.
* Grep the repo for `fixtures/haiku*` and for lines containing both the current `minute_words` and the test `nonce`.
* Disallow hardcoded haiku content anywhere in source.

---

## 5) CI Jobs (reference; GitHub Actions)

**Blocking for PRs (order)**

1. `precommit` — fmt/lint; spec‑extract; regen OpenAPI & Schema; fail on diff.
2. `cdc_consumer` — Pact (CLI) → pact files.
3. `stub_flow` — wiremock stubs + insta snapshots.
4. `provider_verify` — Pact provider verification (orchestratord).
5. `unit_props` — unit + proptest.
6. `determinism` — per engine: two replicas, 64 prompts, byte‑exact (llama.cpp: `--parallel 1 --no-cont-batching`; others: single‑slot/single‑request equivalents).
7. `e2e_haiku` — prefer NVIDIA GPU worker over LAN via **OrchQueue v1** (`/v1/tasks` + stream); if unreachable in CI, run against CPU llama.cpp (Qwen 0.5B) as a CI‑only fallback, still via OrchQueue v1; minute+nonce, metrics delta, ≤ 30 s.
8. `docs_compliance` — spec‑extract + COMPLIANCE.md, linkcheck.

**Nightly**

* `chaos` — failure injections + recovery checks.
* `load_slo` — sustained load; SLO budget assertion.
* `e2e_gpu_optional` — same haiku/determinism on a GPU runner (preferred when available).

**Model cache step (example)**

```bash
HF_HUB_ENABLE_HF_TRANSFER=1 huggingface-cli download \
  Qwen/Qwen2.5-0.5B-Instruct-GGUF qwen2.5-0.5b-instruct-q4_k_m.gguf \
  --local-dir ~/.cache/models --local-dir-use-symlinks False
```

**Server start (CPU)**

```bash
llama-server \
  --model ~/.cache/models/qwen2.5-0.5b-instruct-q4_k_m.gguf \
  --host 127.0.0.1 --port 8080 \
  --metrics --no-webui
```

---

## 6) Developer Loop & Quality Gates (Refined)

Run these in order; second regen run must be diff‑clean.

1. Formatting and lints

```bash
cargo fmt --all -- --check
cargo clippy --all-targets --all-features -- -D warnings
```

2. Regenerators (deterministic)

```bash
cargo xtask regen-openapi
cargo xtask regen-schema
cargo run -p tools-spec-extract --quiet
git diff --exit-code
```

3. Tests (workspace + suites)

```bash
cargo test --workspace --all-features -- --nocapture
cargo test -p orchestratord --test provider_verify -- --nocapture
cargo test -p cli-consumer-tests -- --nocapture
cargo test -p tools-openapi-client -- --nocapture   # trybuild UI
cargo test -p test-harness-bdd -- --nocapture       # BDD placeholders (0 undefined/ambiguous)
```

4. Docs link checker

```bash
bash ci/scripts/check_links.sh
```

5. Convenience wrappers

```bash
cargo xtask ci:haiku:cpu
cargo xtask ci:determinism
```

See also: `README.md` (Quickstart) and `.specs/orchestrator-spec.md` (normative).

## SPEC→SHIP Workflow v2 (Contract‑First, Stub‑First, TDD)

**Status:** Adoptable now · **Scope:** NVIDIA‑only inference (Linux, headless) and multi‑engine (llama.cpp, vLLM, TGI, Triton/TensorRT‑LLM); Orchestrator + pools/scheduler + CLI consumer
**Conformance language:** RFC‑2119 (MUST/SHOULD/MAY)

This file is the authoritative buildbook to take the Orchestrator SPEC to a shippable release with **TDD**, **contract‑first**, **stub‑first**, and **real‑model gates**. Changes to this document require PR + review.

---

## 7) Backpressure, Policies, SLOs (defaults)

* **Queue full policy:** `interactive = reject`, `batch = drop-lru`.
* **Backpressure headers:** `429` + `Retry-After` (seconds) + `X-Backoff-Ms`.
* **Priority classes:** `interactive` (TTFB p95 ≤ 900 ms; 64‑tok p95 ≤ 2.5 s), `batch` (throughput‑oriented).

---

## 8) Security & Tenancy (day‑1)

* **Auth:** API keys (HMAC). Future: OIDC/JWT.
* **Quotas:** per‑tenant concurrent jobs, tokens/min, KV‑MB; reject before enqueue when exceeding.

---

## 9) Definition of Done (per requirement)

For each `ORCH-XXXX`:

1. Contract coverage (OpenAPI/Schema) present; 2) Consumer pact interaction exists; 3) Provider verification passes; 4) Unit/property tests cover edge cases; 5) Observability proves it (metric/log); 6) `requirements/index.yaml` links req → tests → code.

---

## 10) Rollout & Rollback

* Canary via label selectors or % splits. Rollback **MUST** be one action.
* Determinism note: new engine commit/version ⇒ **new replica set**; do not mix with old.

---

## 11) Env Conventions

* `TZ=Europe/Amsterdam` — enforced for E2E‑Haiku.
* `REQUIRE_REAL_LLAMA=1` — E2E must use a real Worker (GPU preferred; CPU is CI‑only fallback).
* `ORCH_REQUIRE_SAME_ENGINE=1` — enforce engine/version pin within replica sets.
* `ORCH_SEED_DEFAULT=hash(job_id)` — seed injection policy when omitted.

---

## 12) Notes

* Keep SPEC IDs stable; deprecate with `-DEPR`, never reuse.
* Treat metrics as contracts: changing names/labels is a breaking change.
* Haiku is a **human‑plausibility** test, not a content validator.
