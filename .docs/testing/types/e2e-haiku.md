# E2E Haiku (GPU) — Guide and Proof Bundle

## What

Integration anti‑cheat test that proves a real decode path on a GPU by requiring
the model to emit the current minute spelled out in letters within a haiku.

Notes:

- Despite the name, this test is best thought of as an integration test (not a full e2e of the entire platform). It primarily exercises orchestrator ↔ engine streaming and can be scoped to validate the engine provisioner path.
- Purpose is anti‑cheating: it must be impossible to pass using fixtures, canned outputs, or mock engines.

## Where

- `test-harness/e2e-haiku/`.
- Proof bundles: `<crate>/.proof_bundle/e2e-haiku/<run_id>/` for crates emitting artifacts; harness may also emit under its own crate.

## Why (Anti‑cheat definition)

- The prompt includes the current minute in words (e.g., "twenty‑nine") generated by the client at stream start, optionally combined with a nonce. This ensures the output cannot be pre‑baked.
- The test must run against a real model/engine on GPU. Mock/stub engines are disallowed for this test.
- We verify tokens were actually emitted (metrics delta), not just an HTTP success.

## Inputs & Prompt

- Compute minute words at stream start (client side). Example English mapping: `29 → "twenty‑nine"`.
- Recommended to include an 8‑character nonce to further eliminate caching (e.g., `nonce: abc123xy`).
- Example prompt (simplified):

  ```text
  please write a haiku that includes the word "twenty‑nine"
  ```

## HTTP Contract (OpenAPI v2)

- Enqueue: `POST /v2/tasks` with a valid `TaskRequestV2`.
- Stream: `GET /v2/tasks/{task_id}/events` (SSE). Events: `started` → `token*` → optional `metrics*` → `end` (or `error`).
- Optional verbose: `?verbose=true` to receive additional human‑narrated breadcrumbs in selected `metrics` frames.
- Cancel (if needed): `POST /v2/tasks/{task_id}/cancel`.

## Env

- `REQUIRE_REAL_LLAMA=1` (must be set)
- `LLORCH_RUN_ID` (recommended)
  - If the harness derives minute words in a specific timezone, document it (e.g., Europe/Amsterdam) and keep it consistent run‑to‑run.

## Artifacts (see template)

- `admission.json` — Admission response and headers
- `sse_transcript.ndjson` — ordered SSE frames `{ event, data, ts }`
- `metrics_snapshot.json` — selected Prometheus scrape(s) before/after
- `gpu_env.json` — GPU model/driver/runtime info
- `logs.jsonl` — optional orchestrator JSON logs filtered by correlation id
- `verification.json` — minute word and nonce used, checks performed and results
- `run_log_redacted.md` — human‑readable run notes, without secrets
- `test_report.md` — summary and pointers to artifacts

## Acceptance Criteria (Anti‑cheat)

- Real engine/worker used; `REQUIRE_REAL_LLAMA=1` enforced.
- No mocks/stubs; fail if a mock engine is detected or `/metrics` is unavailable.
- Prompt includes the current minute in words; output contains that word exactly once (per harness rules).
- Optional nonce is respected (not echoed unless prompt requests it explicitly).
- Metrics token delta observed (`tokens_out_total` increases > 0) and engine/version surfaced.
- Repository scan (if enabled in CI) finds no fixtures or hardcoded outputs that combine both the minute word and the nonce.
- Finishes within ≤ 30 seconds; a single retry is allowed if the minute flips mid‑run.

## Links

- Template: `.proof_bundle/templates/e2e-haiku/README.md`
- Index: `.docs/testing/TEST_TYPES_GUIDE.md`
- Plan: `.plan/73_e2e_haiku.md`
- Harness: `test-harness/e2e-haiku/`
