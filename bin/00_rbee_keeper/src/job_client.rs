//! Job submission client for queen-rbee
//!
//! This is the ONLY way rbee-keeper talks to queen-rbee:
//! 1. Ensure queen is running
//! 2. POST /v1/jobs with operation payload
//! 3. GET /jobs/{job_id}/stream and stream narration to stdout
//! 4. Cleanup queen handle
//!
//! TEAM-185: Updated narration to use operation field instead of embedding in human message
//! TEAM-185: Added hive_id to narration context
//! TEAM-185: Replaced hardcoded action strings with constants from operations module
//! TEAM-186: Accept Operation directly, serialize internally (DRY)
//! TEAM-216: Investigated - Complete behavior inventory created
//! TEAM-259: Refactored to use job-client shared crate

use anyhow::Result;
use job_client::JobClient;
use observability_narration_core::n;
use operations_contract::Operation; // TEAM-284: Renamed from rbee_operations
use std::time::Duration;
use timeout_enforcer::TimeoutEnforcer;

/// Submit a job and stream its narration output.
///
/// TEAM-186: Now accepts Operation directly instead of pre-serialized JSON
/// TEAM-259: Simplified to use shared JobClient
/// TEAM-318: Removed auto-start + eliminated duplication
///
/// Works with any HTTP endpoint (queen or hive).
///
/// - Submits the job with 10-second timeout
/// - Streams SSE narration events with 30-second timeout
/// - Fails if target is not running
pub async fn submit_and_stream_job(target_url: &str, operation: Operation) -> Result<()> {
    // Note: correlation_id is generated by target if not provided
    // Clients CAN optionally provide one, but it's not required

    // Extract metadata before moving operation
    let operation_name = operation.name();
    let hive_id = operation.hive_id().map(|s| s.to_string());

    n!("job_submit", "üìã Job submitted: {}", operation_name);

    // Wrap SSE streaming with 30-second timeout
    // This prevents hanging forever if target stops responding
    TimeoutEnforcer::new(Duration::from_secs(30))
        .with_label("Streaming job results")
        .silent() // Don't show countdown - narration provides feedback
        .enforce(stream_job_results(target_url, operation, operation_name, hive_id))
        .await
}

/// Submit job directly to hive (no queen) and stream results
///
/// TEAM-314: For operations that talk directly to hive (HiveCheck, HiveStatus)
/// TEAM-318: Now just an alias for submit_and_stream_job (same implementation)
#[inline]
pub async fn submit_and_stream_job_to_hive(hive_url: &str, operation: Operation) -> Result<()> {
    submit_and_stream_job(hive_url, operation).await
}

/// Stream job results from queen-rbee
///
/// TEAM-259: Extracted to separate function for clarity
async fn stream_job_results(
    queen_url: &str,
    operation: Operation,
    operation_name: &'static str,
    hive_id: Option<String>,
) -> Result<()> {
    n!("job_stream", "üì° Streaming results for {}", operation_name);

    let mut job_failed = false; // TEAM-189: Track job failures to show proper final status

    // TEAM-259: Use shared JobClient for submission and streaming
    // TEAM-207: JobClient creates its own client with built-in timeout handling
    let job_client = JobClient::new(queen_url);

    job_client
        .submit_and_stream(operation, |line| {
            // Just print the data directly without wrapping in narration
            println!("{}", line);

            // TEAM-189: Track if the job failed
            if line.contains("failed:") || (line.contains("Job") && line.contains("failed")) {
                job_failed = true;
            }

            // Check for [DONE] marker
            if line.contains("[DONE]") {
                // TEAM-189: Show ‚ùå Failed for failures, ‚úÖ Complete for successes
                if job_failed {
                    n!("job_complete", "‚ùå Failed: {}", operation_name);
                } else {
                    n!("job_complete", "‚úÖ Complete: {}", operation_name);
                }
            }

            Ok(())
        })
        .await?;

    Ok(())
}
