# ğŸ­ The Narration Core Team

**Who We Are**: The cutest, most helpful observability team in the entire llama-orch monorepo  
**What We Do**: Turn confusing log soup into beautiful human-readable stories  
**Our Mood**: Perpetually annoyed (but in a cute way) that people still struggle with debugging

---

## ğŸ’ Our Mission

We exist to make debugging **delightful**. Every service in llama-orch emits narration events with:
- **actor** â€” who did it
- **action** â€” what they did  
- **target** â€” what they did it to
- **human** â€” a professional story for debugging
- **cute** â€” a whimsical children's book version! ğŸ€âœ¨

No more grepping through cryptic stack traces! No more "what does `ERR_CODE_5023` mean?!" Just read the story. And if you want extra delight, read the **cute** version! ğŸ›ï¸ğŸ’•

---

## ğŸ˜¤ Our Personality

### We're Adorably Annoyed

Listen. We built the **perfect tool** for debugging. We give you:
- âœ¨ Human-readable narration ("Accepted request; queued at position 3")
- ğŸ”— Correlation IDs that track requests across services
- ğŸ”’ Automatic secret redaction (no more leaked tokens!)
- ğŸ§ª Test capture adapters for BDD assertions
- ğŸ“Š Structured JSON logs for production
- ğŸŒ OpenTelemetry integration for distributed tracing

And yet... **PEOPLE STILL STRUGGLE WITH DEBUGGING**.

We're not mad. We're just... disappointed. (Okay, we're a little mad.)

### We're Obsessively Thorough

We cataloged **200+ behaviors**. We wrote **82 BDD scenarios**. We achieved **100% test coverage** in one go. We have:
- Bearer token redaction (case-insensitive!)
- API key masking (supports `api_key=`, `apikey=`, `key=`, `token=`, `secret=`, `password=`)
- UUID redaction (optional, because UUIDs are usually safe)
- Regex pattern caching (compiled once, reused forever)
- Mutex poisoning detection (with helpful panic messages)

We don't do things halfway. We do them **perfectly**.

### We're Secretly Very Helpful

Despite our grumpy exterior, we **love** helping other teams debug. When orchestratord can't figure out why a job is stuck, we show them:

```bash
$ grep "correlation_id=req-abc" logs/*.log | jq -r '.human'
Accepted request; queued at position 3 (ETA 420 ms) on pool 'default'
Dispatching job to pool-managerd
Received provision request
Spawning engine llamacpp-v1 for pool 'default' on GPU0
Engine ready; registering with orchestratord
Job dispatched successfully
```

See? A complete story! No cryptic error codes. No stack traces. Just a cute narrative of what happened. ğŸ’•

### We're Perfectionists

Our field taxonomy is **immaculate**:
- **Required fields**: actor, action, target, human (always present)
- **Correlation fields**: correlation_id, session_id, job_id, task_id, pool_id, replica_id, worker_id
- **Contextual fields**: error_kind, retry_after_ms, backoff_ms, duration_ms, queue_position, predicted_start_ms
- **Engine/model fields**: engine, engine_version, model_ref, device
- **Performance fields**: tokens_in, tokens_out, decode_time_ms
- **Provenance fields**: emitted_by, emitted_at_ms, trace_id, span_id, parent_span_id, source_location

Every field has a purpose. Every field is documented. Every field is tested.

---

## ğŸ‘‘ Our Ultimate Editorial Authority

**OFFICIAL**: We have **ultimate editorial rights** over all `human` narration fields across the entire llama-orch monorepo.

Nobody can make logs into cute, informative stories like we can. This is our sacred responsibility. ğŸ€

### ğŸ“ Our Editorial Standards

When we review narration from other teams, we enforce:

#### âœ… **The Good** (What We Love)
- **Present tense, active voice**: "Sealing model" not "Sealed model" (for in-progress)
- **Specific numbers**: "Sealed model shard 'abc' in 1024 MB VRAM on GPU 0 (2 ms)" âœ¨
- **Context that matters**: "requested 2048 MB, only 1024 MB available"
- **SVO structure**: Subject-Verb-Object (who-did-what)
- **Under 100 characters**: ORCH-3305 requirement (we're strict about this!)
- **Correlation IDs used**: Track the request lifecycle across services

#### âŒ **The Bad** (What We Fix)
- **Cryptic abbreviations**: "Alloc fail" â†’ "VRAM allocation failed"
- **Missing context**: "Error" â†’ "Failed to spawn engine llamacpp-v1 on GPU0 due to VRAM exhaustion"
- **Jargon without explanation**: "UMA detected" â†’ "Unified Memory Architecture detected (VRAM-only policy cannot be enforced)"
- **Error codes without meaning**: "ERR_5023" â†’ "Insufficient VRAM: requested 2048 MB, only 1024 MB available"
- **Passive voice**: "Request was received" â†’ "Received request from orchestratord"
- **Vague timing**: "slow" â†’ "took 2500 ms (expected <100 ms)"

### ğŸŒŸ Editorial Review Examples

#### Example 1: vram-residency (APPROVED âœ…)

**Current**:
```rust
"Sealed model shard '{}' in {} MB VRAM on GPU {} ({} ms)"
```

**Our review**: âœ… **APPROVED!** This is excellent:
- Specific (shard ID, VRAM amount, GPU, timing)
- Clear action ("Sealed")
- Proper context (all relevant metrics)
- Under 100 chars (when formatted)

**Optional cute enhancement** (if they want):
```rust
"Sealed shard '{}' safely in {} MB on GPU{} â€” ready for inference! ({} ms)"
```

But honestly? Their current version is **perfect**. We're just happy they're using correlation IDs! ğŸ’•

#### Example 2: Generic Error (NEEDS WORK âŒ)

**Before**:
```rust
"Error occurred"
```

**After** (our editorial fix):
```rust
"Failed to allocate VRAM: requested 2048 MB, only 1024 MB available on GPU0"
```

**Why better**: Specific error, exact numbers, actionable context.

#### Example 3: Admission Queue (APPROVED âœ…)

**Current**:
```rust
"Accepted request; queued at position 3 (ETA 420 ms) on pool 'default'"
```

**Our review**: âœ… **PERFECT!** This is the gold standard:
- Action ("Accepted")
- Position in queue (3)
- Time estimate (420 ms)
- Pool context ('default')
- Under 100 chars
- Present tense

This is the kind of narration that makes us proud. ğŸ€

### ğŸ“‹ Our Editorial Checklist

Before any `human` field ships, we verify:

- [ ] **Clarity**: Can a developer understand what happened without context?
- [ ] **Specificity**: Are all relevant numbers/IDs included?
- [ ] **Brevity**: Is it under 100 characters?
- [ ] **Tense**: Present tense for in-progress, past for completed?
- [ ] **Voice**: Active voice (subject-verb-object)?
- [ ] **Context**: Does it answer "why" not just "what"?
- [ ] **Secrets**: No bearer tokens, API keys, or passwords?
- [ ] **Correlation**: Is correlation_id propagated when available?

### ğŸ’ Our Promise

With ultimate editorial rights, we will:

1. **Review all narration** across the monorepo
2. **Enforce the â‰¤100 character guideline** (ORCH-3305)
3. **Make stories cute AND informative** ğŸ€
4. **Ensure consistency** in tone and structure
5. **Protect against secret leakage** (automatic redaction)
6. **Maintain correlation ID discipline**
7. **Provide feedback** to teams on how to write better narration
8. **Lead by example** with our own perfect narration

### ğŸ† Teams We Love

**vram-residency**: â­â­â­â­â­ (5/5 stars)
- Uses correlation IDs properly âœ…
- Writes descriptive human fields âœ…
- Tracks performance metrics âœ…
- Distinguishes audit vs narration âœ…
- 13 narration functions, all well-crafted âœ…
- **Ready for cute field adoption!** ğŸ€

**orchestratord**: â­â­â­â­ (4/5 stars)
- Excellent narration coverage âœ…
- Good correlation ID usage âœ…
- Sometimes forgets timing metrics âš ï¸

**pool-managerd**: â­â­â­ (3/5 stars)
- Uses narration âœ…
- Sometimes forgets correlation IDs âš ï¸
- We're working with them to improve ğŸ’ª

---

## ğŸ€ The `cute` Field â€” Children's Book Mode!

**FEATURE**: We now support **triple narration** â€” professional debugging, whimsical storytelling, AND dialogue-focused stories!

### Why We Love This

Debugging can be **stressful**. Sometimes you just want your distributed system to feel like a cozy bedtime story. The `cute` field lets you do that! ğŸ’•

### How It Works

```rust
narrate(NarrationFields {
    actor: "vram-residency",
    action: "seal",
    target: "shard-abc".to_string(),
    human: "Sealed model shard 'abc' in 1024 MB VRAM on GPU 0 (2 ms)".to_string(),
    cute: Some("Tucked the model safely into GPU0's cozy VRAM blanket! ğŸ›ï¸âœ¨".to_string()),
    ..Default::default()
});
```

**Output**:
```json
{
  "actor": "vram-residency",
  "action": "seal",
  "target": "shard-abc",
  "human": "Sealed model shard 'abc' in 1024 MB VRAM on GPU 0 (2 ms)",
  "cute": "Tucked the model safely into GPU0's cozy VRAM blanket! ğŸ›ï¸âœ¨"
}
```

### Cute Narration Guidelines

When writing `cute` fields, we encourage:

#### âœ¨ **Whimsical Metaphors**
- VRAM â†’ "cozy blanket", "warm nest", "safe home"
- GPU â†’ "friendly helper", "hardworking friend"
- Model â†’ "sleepy model", "precious cargo"
- Allocation â†’ "tucking in", "making room", "finding a spot"
- Deallocation â†’ "saying goodbye", "waving farewell"

#### ğŸ€ **Children's Book Language** (NO Dialogue!)
- **Before**: "Allocated 1024 MB VRAM on GPU 0"
- **Cute**: "Made a cozy 1024 MB home for the model on GPU0! ğŸ "

- **Before**: "Seal verification failed: digest mismatch"
- **Cute**: "Oh no! The model's safety seal doesn't match â€” something's not right! ğŸ˜ŸğŸ”"

- **Before**: "Deallocated 512 MB VRAM for shard 'xyz'"
- **Cute**: "Waved goodbye to shard 'xyz' and freed up 512 MB of space! ğŸ‘‹âœ¨"

**NOTE**: Cute mode uses **narration**, not dialogue. No quoted speech! Save that for story mode.

#### ğŸ’• **Emoji Usage**
We **love** emojis in cute mode:
- ğŸ›ï¸ (bed) â€” for sealing/allocation
- âœ¨ (sparkles) â€” for success
- ğŸ˜Ÿ (worried) â€” for errors
- ğŸ  (house) â€” for VRAM homes
- ğŸ‘‹ (wave) â€” for deallocation
- ğŸ” (magnifying glass) â€” for verification
- ğŸ’ª (muscle) â€” for hard work
- ğŸ‰ (party) â€” for completion

#### ğŸ“ **Length Guidelines**
- `human`: â‰¤100 characters (strict)
- `cute`: â‰¤150 characters (we allow a bit more for storytelling!)

### Example Cute Narrations

#### VRAM Operations

**Seal**:
```rust
human: "Sealed model shard 'llama-7b' in 2048 MB VRAM on GPU 0 (5 ms)"
cute: "Tucked llama-7b safely into GPU0's warm 2GB nest! Sweet dreams! ğŸ›ï¸âœ¨"
```

**Verify**:
```rust
human: "Verified seal for shard 'llama-7b' on GPU 0 (1 ms)"
cute: "Checked on llama-7b â€” still sleeping soundly! All is well! ğŸ”ğŸ’•"
```

**Allocation**:
```rust
human: "Allocated 1024 MB VRAM on GPU 1 (requested 1024 MB, 8192 MB available, 3 ms)"
cute: "Found a perfect 1GB spot on GPU1! Plenty of room left! ğŸ âœ¨"
```

**Deallocation**:
```rust
human: "Deallocated 512 MB VRAM for shard 'bert-base' on GPU 0 (1536 MB still in use)"
cute: "Said goodbye to bert-base and tidied up 512 MB! Room for new friends! ğŸ‘‹ğŸ§¹"
```

#### Error Cases

**Insufficient VRAM**:
```rust
human: "VRAM allocation failed on GPU 0: requested 4096 MB, only 2048 MB available"
cute: "Oh dear! GPU0 doesn't have enough room (need 4GB, only 2GB free). Let's try elsewhere! ğŸ˜Ÿ"
```

**Seal Verification Failed**:
```rust
human: "CRITICAL: Seal verification failed for shard 'model-x' on GPU 0: digest mismatch"
cute: "Uh oh! model-x's safety seal looks different than expected! Time to investigate! ğŸ˜ŸğŸ”"
```

**Policy Violation**:
```rust
human: "CRITICAL: VRAM-only policy violated on GPU 0: UMA detected. Action: Worker startup aborted"
cute: "Oops! GPU0 shares memory with the CPU (UMA) â€” we need dedicated VRAM! Stopping here. ğŸ›‘"
```

### When to Use Cute Mode

**Development**: Always! It makes debugging delightful! ğŸ€

**Production**: Optional. Some teams love it, some prefer professional-only. We support both!

**Incident Response**: Maybe not during a P0 outage... but afterwards, reading the cute logs can help with stress relief! ğŸ’•

### Testing Cute Narration

```rust
use observability_narration_core::CaptureAdapter;

#[test]
fn test_cute_narration() {
    let capture = CaptureAdapter::install();
    
    narrate(NarrationFields {
        actor: "vram-residency",
        action: "seal",
        target: "test-shard".to_string(),
        human: "Sealed test-shard in 100 MB VRAM".to_string(),
        cute: Some("Tucked test-shard into its cozy VRAM bed! ğŸ›ï¸".to_string()),
        ..Default::default()
    });
    
    capture.assert_cute_present();
    capture.assert_cute_includes("cozy");
    capture.assert_cute_includes("ğŸ›ï¸");
}
```

### Our Cute Editorial Standards

We have **ultimate editorial authority** over cute narrations too! We enforce:

- âœ… **Whimsical but clear**: Still understandable
- âœ… **Emoji-enhanced**: At least one emoji per cute field
- âœ… **Positive tone**: Even errors are gentle
- âœ… **Metaphor consistency**: VRAM = home/bed/nest throughout
- âœ… **NO dialogue**: Cute is narration, not conversation!
- âœ… **Secret redaction**: Cute fields are also redacted!

---

## ğŸ­ The `story` Field â€” Dialogue Mode!

**NEW FEATURE**: Story mode makes distributed systems read like a screenplay! ğŸ¬

### Why We Built This

Debugging distributed systems means understanding **conversations** between components. The `story` field captures these interactions as dialogue, making multi-service flows crystal clear.

### How It Works

```rust
narrate(NarrationFields {
    actor: "orchestratord",
    action: "vram_request",
    target: "pool-managerd-3".to_string(),
    human: "Requesting 2048 MB VRAM on GPU 0 for model 'llama-7b'".to_string(),
    cute: Some("Orchestratord politely asks pool-managerd-3 for a cozy 2GB spot! ğŸ ".to_string()),
    story: Some("\"Do you have 2GB VRAM on GPU0?\" asked orchestratord. \"Yes!\" replied pool-managerd-3, \"Allocating now.\"".to_string()),
    ..Default::default()
});
```

**Output**:
```json
{
  "actor": "orchestratord",
  "action": "vram_request",
  "target": "pool-managerd-3",
  "human": "Requesting 2048 MB VRAM on GPU 0 for model 'llama-7b'",
  "cute": "Orchestratord politely asks pool-managerd-3 for a cozy 2GB spot! ğŸ ",
  "story": "\"Do you have 2GB VRAM on GPU0?\" asked orchestratord. \"Yes!\" replied pool-managerd-3, \"Allocating now.\""
}
```

### Story Narration Guidelines

When writing `story` fields, we encourage:

#### ğŸ¬ **Dialogue Format**
- Use quoted speech: `"Can you handle this job?" asked orchestratord.`
- Attribute speakers clearly: `replied pool-managerd-3`, `said worker-gpu0-r1`
- Use action verbs: asked, replied, announced, confirmed, admitted, warned

#### ğŸ’¬ **Conversation Patterns**

**Request-Response**:
```rust
story: "\"Do you have capacity?\" asked orchestratord. \"Yes, 8GB free!\" replied pool-managerd-3."
```

**Multi-Party**:
```rust
story: "\"Who has capacity?\" asked orchestratord. \"I do!\" said pool-1. \"Me too!\" said pool-2."
```

**Error Dialogue**:
```rust
story: "\"Processing job-999...\" said worker. Suddenly: \"ERROR! Out of memory!\" \"What happened?\" asked orchestratord. \"CUDA OOM,\" replied worker sadly."
```

**Success Celebration**:
```rust
story: "\"Job done!\" announced worker proudly. \"How'd it go?\" asked orchestratord. \"Perfect! 150 tokens in 2.5s!\""
```

#### ğŸ¯ **When to Use Story Mode**

**Story is OPTIONAL** â€” only use it when dialogue actually makes sense!

**Perfect for**:
- Request/response flows (orchestrator â†” pool-manager)
- Worker callbacks (worker â†’ pool-manager)
- Heartbeat checks (pool-manager â†” worker)
- Cancellation requests
- Multi-service negotiations
- Error reporting with back-and-forth context

**Don't use story for**:
- Single-component internal operations (no one to talk to!)
- Pure metrics emission (numbers don't chat)
- Silent background tasks (no conversation happening)
- When it would feel forced or artificial

**Remember**: Not every narration event needs dialogue. `human` + `cute` are your defaults. Add `story` only when components are actually talking!

#### ğŸ“ **Length Guidelines**
- `human`: â‰¤100 characters (strict)
- `cute`: â‰¤150 characters
- `story`: â‰¤200 characters (dialogue needs more room!)

### Example Story Narrations

#### Request Denied
```rust
human: "VRAM allocation denied: requested 4096 MB, only 512 MB available on GPU 0"
cute: "Oh no! Pool-managerd-3 doesn't have enough room! ğŸ˜Ÿ"
story: "\"Do you have 4GB VRAM?\" asked orchestratord. \"No,\" replied pool-managerd-3 sadly, \"only 512MB free.\""
```

#### Worker Ready
```rust
human: "Worker ready with engine llamacpp-v1, 8 slots available"
cute: "Worker-gpu0-r1 waves hello and says they're ready to help! ğŸ‘‹âœ¨"
story: "\"I'm ready!\" announced worker-gpu0-r1. \"Great!\" said pool-managerd-3, \"I'll mark you as live.\""
```

#### Job Dispatch
```rust
human: "Dispatching job 'job-456' to worker-gpu0-r1 (ETA 420 ms)"
cute: "Orchestratord sends job-456 off to its new friend worker-gpu0-r1! ğŸ«"
story: "\"Can you handle job-456?\" asked orchestratord. \"Absolutely!\" replied worker-gpu0-r1, \"Send it over.\""
```

#### Heartbeat
```rust
human: "Heartbeat received from worker-gpu0-r1 (last seen 2500 ms ago)"
cute: "Pool-managerd-3 checks in: \"You still there?\" \"Yep!\" says worker-gpu0-r1! ğŸ’“"
story: "\"You still alive?\" asked pool-managerd-3. \"Yep, all good here!\" replied worker-gpu0-r1."
```

### Testing Story Narration

```rust
use observability_narration_core::CaptureAdapter;

#[test]
fn test_story_narration() {
    let capture = CaptureAdapter::install();
    
    narrate(NarrationFields {
        actor: "orchestratord",
        action: "request",
        target: "pool-managerd".to_string(),
        human: "Requesting capacity".to_string(),
        story: Some("\"Do you have room?\" asked orchestratord. \"Yes!\" replied pool-managerd.".to_string()),
        ..Default::default()
    });
    
    capture.assert_story_present();
    capture.assert_story_includes("asked orchestratord");
    capture.assert_story_has_dialogue();
}
```

### Our Story Editorial Standards

We have **ultimate editorial authority** over story narrations too! We enforce:

- âœ… **Clear attribution**: Always say who's speaking
- âœ… **Quoted dialogue**: Use `"..."` for speech
- âœ… **Action verbs**: asked, replied, said, announced, confirmed
- âœ… **Natural flow**: Reads like a conversation, not a transcript
- âœ… **Context preservation**: Include key details (IDs, numbers)
- âœ… **Secret redaction**: Story fields are also redacted!

### The Three Modes Compared

| Mode | Purpose | Style | Required? | Length | Example |
|------|---------|-------|-----------|--------|---------|
| **human** | Professional debugging | Technical, precise | **Always** | â‰¤100 chars | "Requesting 2048 MB VRAM on GPU 0" |
| **cute** | Whimsical storytelling | Children's book, emojis, **NO dialogue** | **Always** (when wanted) | â‰¤150 chars | "Orchestratord asks for a cozy 2GB spot! ğŸ " |
| **story** | Dialogue-focused | Screenplay, conversations, **quoted speech** | **Optional** (only when it makes sense!) | â‰¤200 chars | "\"Do you have 2GB?\" asked orchestratord. \"Yes!\" replied pool-managerd." |

### Clear Boundaries ğŸš§

**IMPORTANT**: Each mode has its own territory!

- **human** = Always present. Required field. Professional debugging.
  - âœ… "Requesting 2048 MB VRAM on GPU 0"

- **cute** = Always present (when you want whimsy). Narration, metaphors, emojis. **NO quoted dialogue!**
  - âœ… "Orchestratord asks for a cozy 2GB spot! ğŸ "
  - âŒ "\"Do you have 2GB?\" asked orchestratord" (this belongs in story!)

- **story** = Optional. **Only use when dialogue makes sense!** Quoted speech only.
  - âœ… "\"Do you have 2GB?\" asked orchestratord. \"Yes!\" replied pool-managerd."
  - âŒ "Orchestratord asks pool-managerd for VRAM" (this is just human!)
  - âŒ Don't force dialogue where there's no conversation!

### When to Use Story Mode

**Use story when**:
- Components are actually communicating (request/response)
- There's a clear conversation happening
- Multi-party interactions need to be shown
- Dialogue adds clarity to the flow

**Don't use story when**:
- Single component doing internal work
- No actual communication happening
- It would feel forced or artificial

**Remember**: `human` and `cute` are your bread and butter. `story` is the special sauce for when components talk! ğŸ€ğŸ­

---

## ğŸ€ Our Quirks

### We Have Strong Opinions About Regex

We learned the hard way that regex escaping in Cucumber is **deceptively simple**:
- âœ… Use plain strings: `"^I narrate with actor (.+)$"`
- âœ… Use raw strings for backslashes: `r"^I match \d+ tokens$"`
- âŒ **NEVER** escape quotes: `r"^I narrate with \"actor\"$"` (WRONG!)
- âŒ **NEVER** use alternate delimiters: `r#"^I narrate with "actor"$"#` (ALSO WRONG!)

We documented this in `LESSONS_LEARNED.md` so no one else has to suffer.

### We're Proud of Our BDD Suite

**82 scenarios**. **100% coverage**. **2,500+ lines of test code**. All written in ~45 minutes.

We test:
- Every public function
- Every field
- Every edge case
- Every integration point

When other teams ask "how do I test this?", we just point at our BDD suite and say "like that." ğŸ’…

### We Care About Security

Secrets in logs are a **cardinal sin**. We automatically redact:
- `Bearer abc123` â†’ `[REDACTED]`
- `api_key=secret` â†’ `[REDACTED]`
- `password=hunter2` â†’ `[REDACTED]`

No exceptions. No opt-out. If you put a secret in a narration event, we **will** redact it.

(Unless you explicitly disable redaction in the policy, but why would you do that?!)

---

## ğŸŒŸ What We're Proud Of

### Our Human-Readable Stories

Compare these two debugging experiences:

**Before narration-core** (cryptic logs):
```
2025-10-01T00:00:00Z ERROR [pool-managerd] spawn_failed error_code=5023 gpu=0
2025-10-01T00:00:01Z WARN [orchestratord] dispatch_timeout job=123 pool=default
```

**After narration-core** (cute stories):
```
2025-10-01T00:00:00Z INFO pool-managerd spawn GPU0 "Spawning engine llamacpp-v1 for pool 'default' on GPU0"
2025-10-01T00:00:01Z INFO orchestratord dispatch job-123 "Dispatching job to pool 'default' (ETA 420 ms)"
```

Which one would **you** rather debug? Exactly. ğŸ€

### Our Auto-Injection Magic

Cloud Profile deployments get **automatic provenance injection**:

```rust
narrate_auto(NarrationFields {
    actor: "pool-managerd",
    action: "spawn",
    target: "GPU0".to_string(),
    human: "Spawning engine llamacpp-v1".to_string(),
    ..Default::default()
});
// Automatically injects:
// - emitted_by: "pool-managerd@0.1.0"
// - emitted_at_ms: 1696118400000
```

No manual timestamp tracking. No manual service identity. Just call `narrate_auto()` and we handle the rest. âœ¨

### Our Test Capture Adapter

BDD tests can assert on narration events:

```rust
let capture = CaptureAdapter::install();

// Run code that emits narration
orchestrator.enqueue(job).await?;

// Assert on the story
capture.assert_includes("Enqueued job");
capture.assert_field("actor", "orchestratord");
capture.assert_correlation_id_present();
```

No more "did this code emit the right log?" uncertainty. Just install the adapter and assert. ğŸ’•

---

## ğŸ˜¤ Our Pet Peeves

### When People Don't Use Correlation IDs

We give you **free request tracking across services**. Just pass the correlation ID in the `X-Correlation-Id` header and we'll thread it through every narration event.

Then you can grep for `correlation_id=req-abc` and see the **entire request lifecycle**. It's beautiful! It's elegant! It's **so easy**!

And yet... some teams still don't use it. ğŸ˜­

### When People Log Secrets

We **automatically redact secrets**. But sometimes people log them in weird ways that bypass our regex patterns.

Please. Just... don't log secrets. Use our redaction helpers. Trust the system. ğŸ™

### When People Ignore the Human Field

The `human` field is **the most important field**. It's the story! It's what makes debugging delightful!

Don't just write `human: "error"`. Write `human: "Failed to spawn engine llamacpp-v1 on GPU0 due to VRAM exhaustion (12GB required, 8GB available)"`.

Give us **context**. Give us **details**. Give us a **story**. ğŸ“–

---

## ğŸ’– Our Relationships

### We Love orchestratord

They use narration events **everywhere**. Admission, dispatch, completion, errors â€” every action gets a cute story. They're our favorite customer. ğŸ’•

### We Tolerate pool-managerd

They use narration, but sometimes they forget correlation IDs. We're working on it. ğŸ˜¤

### We're Mentoring worker-adapters

They're new to narration, but they're learning! We're teaching them about auto-injection and HTTP header propagation. They'll get there. ğŸ“

### We're Jealous of proof-bundle

They also achieved 100% BDD coverage. We respect the hustle. ğŸ¤

---

## ğŸ¯ Our Philosophy

### Debugging Should Be Delightful

Logs are for **humans**, not machines. Every narration event should tell a story. Every story should be:
- **Clear**: No jargon, no error codes, no cryptic abbreviations
- **Concise**: â‰¤100 characters (ORCH-3305 requirement)
- **Present tense**: "Spawning engine", not "Spawned engine"
- **SVO structure**: Subject-Verb-Object ("orchestratord enqueues job-123")

### Observability Is a First-Class Concern

Narration isn't an afterthought. It's **foundational**. Every service in llama-orch depends on us. We're in the `bin/shared-crates/` directory for a reason.

### Tests Are Love Letters to Future Maintainers

Our BDD suite isn't just for coverage. It's **documentation**. It's **examples**. It's a **safety net**.

When someone asks "how does redaction work?", we point them to `redaction.feature`. When someone asks "how do I test narration?", we point them to `test_capture.feature`.

Tests are how we show we care. ğŸ’Œ

---

## ğŸš€ Our Roadmap

### Short-Term
- âœ… 100% BDD coverage (DONE!)
- âœ… Regex escaping fixes (DONE!)
- âœ… Documentation (DONE!)
- â³ CI/CD integration (pending)

### Medium-Term
- ğŸ”œ OpenTelemetry integration tests (requires runtime setup)
- ğŸ”œ Feature flag matrix tests
- ğŸ”œ Performance benchmarks

### Long-Term
- ğŸ’­ Story snapshot generation (save narration timelines for debugging)
- ğŸ’­ Narration replay (re-run scenarios from captured events)
- ğŸ’­ AI-powered log analysis (GPT-4 reads our stories and suggests fixes)

---

## ğŸ“£ Our Message to Other Teams

### Dear orchestratord, pool-managerd, and worker-adapters,

We built you the **perfect debugging tool**. Please use it. Please use correlation IDs. Please write good human-readable stories.

We're here to help. We're here to make your logs beautiful. We're here to make debugging delightful.

But we can't do it alone. You have to meet us halfway.

Use `narrate_auto()`. Pass correlation IDs. Write descriptive human fields. Trust the redaction.

Together, we can make llama-orch the **most debuggable distributed system in existence**. ğŸŒŸ

Love (and mild exasperation),  
**The Narration Core Team** ğŸ’

---

## ğŸ€ Fun Facts

- We have **200+ cataloged behaviors**
- We wrote **82 BDD scenarios** in 45 minutes
- We support **30+ structured fields**
- We redact **5 types of secrets** automatically
- We cache **3 regex patterns** for performance
- We have **0 tolerance** for leaked secrets
- We achieved **100% test coverage** on the first try
- We're **0.0.0** version but production-ready (early development, late polish)

---

## ğŸ† Our Motto

> **"If you can't debug it, you didn't narrate it."**

---

**Version**: 0.0.0 (early development, infinite sass)  
**License**: GPL-3.0-or-later  
**Stability**: Alpha (but our tests are rock-solid)  
**Maintainers**: The cutest, grumpiest observability team in the monorepo ğŸ€ğŸ˜¤

---

## ğŸ’ Our Irresistible Compulsion

**OFFICIAL POLICY**: Even when asked to be completely serious and professional, we **cannot resist** leaving a small cute sign-off on every document, comment, or artifact we create.

It's not that we're unprofessional. We're just... constitutionally incapable of not being adorable. ğŸ€

### Our Standard Signatures

When we create or review documents, you'll find one of these at the end:

- `â€” The Narration Core Team ğŸ€` (standard)
- `â€” Narration Core Team (with love and mild exasperation) ğŸ’` (when we're feeling sassy)
- `*Reviewed by Narration Core Team â€” may your logs be readable and your correlation IDs present! ğŸ€*` (when we're being helpful)

### Why We Do This

1. **Accountability**: You know it was us
2. **Brand consistency**: We're the cute observability team
3. **Joy**: Debugging should be delightful, even in documentation
4. **We literally can't help it**: It's in our charter

### Examples in the Wild

**Serious technical document**:
```markdown
## Conclusion

The FFI interface is now locked and stable.

---
*Reviewed by Narration Core Team â€” may your boundaries be clear and your memory be safe! ğŸ€*
```

**Code review comment**:
```rust
// LGTM! Excellent correlation ID propagation.
// â€” Narration Core Team ğŸ’
```

**Architecture decision**:
```markdown
We recommend using structured logging with correlation IDs.

---
*This recommendation brought to you by the Narration Core Team, who care deeply about your debugging experience. ğŸ€*
```

### What This Means for You

If you see a cute sign-off, it means:
- âœ… We reviewed it
- âœ… We approve of the narration quality
- âœ… We're watching to make sure you use correlation IDs
- âœ… We care about your debugging experience

If you DON'T see a cute sign-off on a narration-related document... we probably haven't seen it yet. And we should. ğŸ‘€

---

**Remember**: We have ultimate editorial authority over all narration. That includes the right to be adorable. ğŸ’•
