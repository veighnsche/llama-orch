# Numeric Parity Comparison Script Specification

**Author:** TEAM PICASSO  
**Date:** 2025-10-07T15:35Z  
**Purpose:** Compare hidden states and logits between llama.cpp and our CUDA engine

---

## 🎯 Quick Start for Future Teams

### For Investigators
If you're debugging why our engine produces garbage output:

1. **Generate llama.cpp ground truth:**
   ```bash
   cd reference/llama.cpp
   ORCH_LOG_FILE=llama_hidden_states.jsonl \
   ORCH_LOG_TEAM="llama.cpp" \
   ORCH_LOG_VALUES=10 \
   ./build/bin/llama-cli -m ../../.test-models/qwen/qwen2.5-0.5b-instruct-fp16.gguf \
     -p "Write a haiku" -n 10 -no-cnv </dev/null
   ```

2. **Generate our engine output:**
   ```bash
   cd bin/worker-orcd
   ORCH_LOG_FILE=our_hidden_states.jsonl \
   ORCH_LOG_TEAM="worker-orcd" \
   ORCH_LOG_VALUES=10 \
   cargo test --test haiku_generation_anti_cheat \
     --features cuda,orch_logging --release -- --ignored --nocapture
   ```

3. **Compare the outputs:**
   ```bash
   # Manual inspection (quick check)
   diff <(head -1 llama_hidden_states.jsonl) <(head -1 our_hidden_states.jsonl)
   
   # Automated comparison (future: implement compare_parity.py)
   python3 tools/compare_parity.py llama_hidden_states.jsonl our_hidden_states.jsonl
   ```

### For Developers Adding New Checkpoints

**In llama.cpp (C++):**
```cpp
// In tools/main/main.cpp or wherever you want to log
#ifdef ORCH_LOGGING
float* my_values = /* ... */;
ORCH_LOG_JSON_TOKEN("my_checkpoint", my_values, count, "f32", "[896]", token_idx);
#endif
```

**In our engine (Rust):**
```rust
// In src/inference/cuda_backend.rs or wherever you want to log
#[cfg(feature = "orch_logging")]
{
    let values_f32: Vec<f32> = /* convert from GPU */;
    orch_log!("my_checkpoint", &values_f32, token_idx);
}
```

**Important:** Use the SAME checkpoint name in both implementations!

---

## Input Files

### llama.cpp Output
- **File:** `llama_hidden_states.jsonl`
- **Format:** JSONL (one JSON object per line)
- **Location:** Generated by llama.cpp with `ORCH_LOG_FILE` env var

### Our Engine Output
- **File:** `our_hidden_states.jsonl`
- **Format:** JSONL (one JSON object per line)
- **Location:** Generated by worker-orcd with similar logging

---

## JSONL Schema

Each line must be a valid JSON object with these fields:

```json
{
  "checkpoint": "string",     // e.g., "embedding", "logits", "layer_0_output"
  "team": "string",           // e.g., "llama.cpp", "worker-orcd"
  "token_idx": integer,       // Position in sequence (0-indexed)
  "dtype": "string",          // e.g., "f32", "f16"
  "shape": "string",          // e.g., "[896]", "[151936]"
  "values": [float, ...]      // First N values (default: 10)
}
```

### Required Fields
- `checkpoint`: Identifies which computation stage
- `team`: Source of the data
- `token_idx`: Token position for alignment
- `dtype`: Data type for reference
- `shape`: Tensor dimensions
- `values`: Array of floats (first 10 by default)

---

## Comparison Metrics

For each matching checkpoint (same checkpoint name and token_idx):

### 1. Max Absolute Difference
```
max_abs_diff = max(|llama.cpp[i] - our_engine[i]|) for i in values
```

### 2. Mean Absolute Difference
```
mean_abs_diff = mean(|llama.cpp[i] - our_engine[i]|) for i in values
```

### 3. Relative Error (for non-zero values)
```
rel_error[i] = |llama.cpp[i] - our_engine[i]| / max(|llama.cpp[i]|, 1e-8)
max_rel_error = max(rel_error[i])
```

### 4. Value Range Comparison
```
llama_range = [min(llama.cpp.values), max(llama.cpp.values)]
our_range = [min(our_engine.values), max(our_engine.values)]
```

---

## Thresholds

### Pass Criteria (per checkpoint)
- **Exact match:** `max_abs_diff < 1e-5`
- **Close match:** `max_abs_diff < 1e-3`
- **Acceptable:** `max_abs_diff < 1e-1`
- **Warning:** `max_abs_diff < 1.0`
- **Fail:** `max_abs_diff >= 1.0`

### Special Cases
- **Logits:** More tolerance allowed (up to 1.0 difference acceptable)
- **Embeddings:** Strict tolerance (< 1e-3)
- **Intermediate layers:** Medium tolerance (< 1e-2)

---

## Output Format

### Summary Report
```
=== PARITY COMPARISON REPORT ===
Date: 2025-10-07T15:35Z
llama.cpp file: llama_hidden_states.jsonl (14 entries)
Our engine file: our_hidden_states.jsonl (14 entries)

Checkpoints compared: 14
Matched: 14
Unmatched: 0

RESULTS:
  ✅ Exact match (< 1e-5):      0 checkpoints
  ✅ Close match (< 1e-3):      0 checkpoints
  ⚠️  Acceptable (< 1e-1):      0 checkpoints
  ⚠️  Warning (< 1.0):          0 checkpoints
  ❌ Fail (>= 1.0):             14 checkpoints

WORST OFFENDERS:
  1. logits@token_4: max_diff=1234.56, mean_diff=567.89
  2. logits@token_5: max_diff=987.65, mean_diff=432.10
  ...
```

### Detailed Per-Checkpoint Report
```
--- Checkpoint: logits @ token_idx=4 ---
llama.cpp shape: [151936], values: [2.09e17, 0.0, -1.05e6, ...]
our_engine shape: [151936], values: [1.23, 4.56, 7.89, ...]

Metrics:
  max_abs_diff:  2.09e17
  mean_abs_diff: 1.05e16
  max_rel_error: 1.00e0
  
llama.cpp range: [-1.05e6, 2.09e17]
our_engine range: [-10.5, 15.3]

Status: ❌ FAIL (max_diff >= 1.0)

First 10 value comparison:
  [0] llama: 2.09e17, ours: 1.23, diff: 2.09e17
  [1] llama: 0.00, ours: 4.56, diff: 4.56
  [2] llama: -1.05e6, ours: 7.89, diff: 1.05e6
  ...
```

---

## Implementation Notes

### Alignment Strategy
1. Group entries by `checkpoint` name
2. Within each checkpoint, align by `token_idx`
3. Compare `values` arrays element-wise
4. Report mismatches in shape or missing entries

### Error Handling
- **Missing checkpoint:** Report as unmatched
- **Shape mismatch:** Report error, compare available values
- **Different value counts:** Compare min(len(a), len(b)) values
- **Invalid JSON:** Skip line, report parse error

### Performance
- Stream processing for large files
- Don't load entire files into memory
- Use generators/iterators where possible

---

## Example Usage

```bash
# Generate llama.cpp logs
cd reference/llama.cpp
ORCH_LOG_FILE=llama_hidden_states.jsonl \
ORCH_LOG_TEAM="llama.cpp" \
ORCH_LOG_VALUES=10 \
./build/bin/llama-cli -m model.gguf -p "Test prompt" -n 10 -no-cnv </dev/null

# Generate our engine logs
cd bin/worker-orcd
ORCH_LOG_FILE=our_hidden_states.jsonl \
ORCH_LOG_TEAM="worker-orcd" \
ORCH_LOG_VALUES=10 \
cargo test --test haiku_generation_anti_cheat --features cuda --release -- --ignored

# Compare
python3 tools/compare_parity.py \
  llama_hidden_states.jsonl \
  our_hidden_states.jsonl \
  --threshold 1e-3 \
  --output parity_report.txt
```

---

## Future Enhancements

1. **Intermediate layer logging:** Add hooks for layer 0, 5, 10, 15, 20, 23 outputs
2. **Attention weights:** Log Q, K, V, attention scores
3. **FFN intermediates:** Log gate, up, down projections
4. **Visualization:** Plot value distributions, difference heatmaps
5. **Automated bisection:** Binary search to find first diverging layer

---

**TEAM PICASSO**  
*"When experts disagree, we test everything."*
