# C++ Code Cleanup Plan: Remove Rust-Duplicated Code

**Date**: 2025-10-05  
**Status**: READY TO EXECUTE  
**Backup**: User has confirmed backup exists

---

## Understanding: What Exists in Rust

### âœ… COMPLETE in Rust (worker-crates)

1. **`worker-gguf`** (444 lines)
   - GGUF metadata parsing (STUB, but API defined)
   - Architecture detection
   - Config extraction
   - **Status**: API complete, needs real implementation

2. **`worker-tokenizer`** (full implementation)
   - BPE encoder/decoder
   - GGUF vocab parsing
   - HuggingFace JSON support
   - Streaming decoder
   - **Status**: âœ… COMPLETE

3. **`worker-models`** (800+ lines)
   - `QwenModel`, `Phi3Model`, `GPTModel` structs
   - `AdapterFactory` for architecture detection
   - Forward pass trait definitions
   - **Status**: Structs defined, needs FFI wiring

4. **`worker-http`** (full implementation)
   - Axum HTTP server
   - SSE streaming
   - Route handlers
   - **Status**: âœ… COMPLETE

5. **`worker-common`** (full implementation)
   - Error types
   - Sampling config
   - Inference results
   - **Status**: âœ… COMPLETE

6. **`worker-compute`** (trait definition)
   - `ComputeBackend` trait
   - Platform abstraction
   - **Status**: âœ… TRAIT DEFINED

---

## C++ Code to DELETE

### Files to DELETE Entirely

1. **`cuda/src/gguf/header_parser.cpp`** (447 lines)
   - âŒ DELETE: Should be in `worker-gguf`
   - Reason: No GPU needed, pure file I/O

2. **`cuda/src/gguf/header_parser.h`** (173 lines)
   - âŒ DELETE: Should be in `worker-gguf`

3. **`cuda/src/gguf/llama_metadata.cpp`** (308 lines)
   - âŒ DELETE: Should be in `worker-gguf`
   - Reason: No GPU needed, just key-value parsing

4. **`cuda/src/gguf/llama_metadata.h`** (184 lines)
   - âŒ DELETE: Should be in `worker-gguf`

5. **`cuda/src/io/mmap_file.cpp`** (~100 lines)
   - âŒ DELETE: Should be in `worker-gguf`
   - Reason: File I/O, not GPU-specific

6. **`cuda/src/io/mmap_file.h`** (121 lines)
   - âŒ DELETE: Should be in `worker-gguf`

**Total to delete**: ~1,333 lines of C++ code

### Functions to DELETE from Existing Files

1. **`cuda/src/model/gpt_weights.cpp`**
   - âŒ DELETE: `parse_config_from_gguf()` function
   - Reason: Config parsing should be in Rust
   - Keep: `load_from_gguf()` (weight loading to VRAM)

---

## C++ Code to KEEP

### Files to KEEP (GPU-specific)

1. âœ… **`cuda/src/ffi.cpp`** - FFI boundary
2. âœ… **`cuda/src/context.cpp`** - CUDA context
3. âœ… **`cuda/src/model/gpt_weights.cpp`** - Weight loading to VRAM (partial)
4. âœ… **`cuda/src/model/gpt_model.cpp`** - GPU model structure
5. âœ… **`cuda/src/inference_impl.cpp`** - Inference execution
6. âœ… **`cuda/src/kv_cache.cpp`** - KV cache management
7. âœ… **`cuda/kernels/*.cu`** - All CUDA kernels
8. âœ… **`cuda/src/cublas_wrapper.cpp`** - cuBLAS operations
9. âœ… **`cuda/src/device_memory.cpp`** - GPU memory management

**Total to keep**: ~3,305 lines of C++ (GPU-specific)

---

## The New Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ RUST LAYER (bin/worker-crates/)                             â”‚
â”‚                                                              â”‚
â”‚  worker-gguf:                                                â”‚
â”‚    - Parse GGUF metadata                                     â”‚
â”‚    - Extract architecture, config                           â”‚
â”‚    - Return to Rust main                                     â”‚
â”‚                                                              â”‚
â”‚  worker-tokenizer:                                           â”‚
â”‚    - Tokenize prompt                                         â”‚
â”‚    - Decode tokens                                           â”‚
â”‚                                                              â”‚
â”‚  worker-http:                                                â”‚
â”‚    - HTTP server                                             â”‚
â”‚    - SSE streaming                                           â”‚
â”‚                                                              â”‚
â”‚                         â”‚ FFI                                â”‚
â”‚                         â†“                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ C++ CUDA LAYER (bin/worker-orcd/cuda/)                      â”‚
â”‚                                                              â”‚
â”‚  FFI Interface:                                              â”‚
â”‚    - cuda_init(device_id)                                   â”‚
â”‚    - cuda_load_model(ctx, path) â† Rust passes path         â”‚
â”‚    - cuda_inference_start(...)                              â”‚
â”‚    - cuda_inference_next_token(...)                         â”‚
â”‚                                                              â”‚
â”‚  Weight Loading:                                             â”‚
â”‚    - Open GGUF file (mmap)                                  â”‚
â”‚    - Read tensor data                                        â”‚
â”‚    - Allocate GPU memory                                     â”‚
â”‚    - Copy to VRAM                                            â”‚
â”‚                                                              â”‚
â”‚  Inference:                                                  â”‚
â”‚    - Execute CUDA kernels                                    â”‚
â”‚    - Manage KV cache                                         â”‚
â”‚    - Return token IDs                                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Cleanup Steps

### Step 1: Delete GGUF Parser (C++)

```bash
rm cuda/src/gguf/header_parser.cpp
rm cuda/src/gguf/header_parser.h
rm cuda/src/gguf/llama_metadata.cpp
rm cuda/src/gguf/llama_metadata.h
rmdir cuda/src/gguf  # If empty
```

### Step 2: Delete mmap (C++)

```bash
rm cuda/src/io/mmap_file.cpp
rm cuda/src/io/mmap_file.h
```

### Step 3: Update gpt_weights.cpp

Remove `parse_config_from_gguf()` function, keep only weight loading.

### Step 4: Update CMakeLists.txt

Remove deleted files from build.

### Step 5: Update FFI

Simplify FFI - Rust passes parsed config, not path.

---

## Updated FFI Interface

### Before (C++ does everything)

```cpp
extern "C" {
    CudaModel* cuda_load_model(
        CudaContext* ctx,
        const char* model_path,  // C++ parses GGUF
        int* error
    );
}
```

### After (Rust does parsing, C++ does GPU)

```rust
// Rust side
let metadata = worker_gguf::GGUFMetadata::from_file(&path)?;
let config = extract_config(&metadata)?;

// Pass config to C++
let cuda_model = unsafe {
    cuda_load_model_with_config(
        ctx,
        path.as_ptr(),
        &config as *const GPTConfig,
        error
    )
};
```

```cpp
// C++ side
extern "C" {
    CudaModel* cuda_load_model_with_config(
        CudaContext* ctx,
        const char* model_path,
        const GPTConfig* config,  // Rust passes config
        int* error
    ) {
        // Just load weights to VRAM
        auto weights = load_weights_to_vram(model_path, config);
        return new CudaModel(ctx, weights);
    }
}
```

---

## Benefits of Cleanup

1. âœ… **No duplication** - GGUF parsing in ONE place (Rust)
2. âœ… **Clear separation** - Rust = I/O, C++ = GPU
3. âœ… **Easier maintenance** - Changes in ONE place
4. âœ… **Better testing** - Test Rust and C++ separately
5. âœ… **Smaller C++ codebase** - 1,333 fewer lines
6. âœ… **Reusable Rust** - Can use for worker-aarmd (Metal)

---

## Execution Order

1. âœ… Delete C++ GGUF parser files
2. âœ… Delete C++ mmap files
3. âœ… Update gpt_weights.cpp (remove parse_config)
4. âœ… Update CMakeLists.txt
5. âœ… Update FFI interface
6. â¬œ Implement real GGUF parser in Rust (GT-051-REFACTOR)
7. â¬œ Wire everything together

---

## Risk Mitigation

- âœ… User has backup
- âœ… Can revert from backup if needed
- âœ… Delete in stages, test after each
- âœ… Keep GPU-specific code intact

---

**Ready to execute cleanup?**

---
Created by Project Management Team ğŸ“‹
