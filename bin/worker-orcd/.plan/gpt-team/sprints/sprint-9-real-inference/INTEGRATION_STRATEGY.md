# Integration Strategy: Rust worker-crates + C++ CUDA Implementation

**Date**: 2025-10-05  
**Purpose**: Clarify how Rust worker-crates and C++ CUDA code work together  
**Critical**: We have TWO codebases that need to integrate!

---

## The Two Codebases

### 1. Rust Layer (`bin/worker-crates/`)

**What it does**:
- ‚úÖ HTTP server (Axum)
- ‚úÖ GGUF metadata parsing (pure Rust)
- ‚úÖ Tokenization (BPE, HuggingFace)
- ‚úÖ Model adapters (Qwen, Phi-3, GPT, Llama)
- ‚úÖ Architecture detection
- ‚úÖ Sampling logic

**What it DOESN'T do**:
- ‚ùå GPU memory management
- ‚ùå CUDA kernel execution
- ‚ùå Weight loading to VRAM
- ‚ùå Actual inference computation

### 2. C++ CUDA Layer (`bin/worker-orcd/cuda/`)

**What it does**:
- ‚úÖ CUDA context management
- ‚úÖ GPU memory allocation
- ‚úÖ GGUF weight loading to VRAM
- ‚úÖ CUDA kernels (attention, RoPE, RMSNorm, etc.)
- ‚úÖ Inference execution

**What it DOESN'T do**:
- ‚ùå HTTP server
- ‚ùå Tokenization
- ‚ùå Architecture-level abstractions

---

## Current Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ RUST LAYER (bin/worker-crates/)                             ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ
‚îÇ  ‚îÇ worker-http  ‚îÇ  ‚îÇ worker-gguf  ‚îÇ  ‚îÇ worker-      ‚îÇ     ‚îÇ
‚îÇ  ‚îÇ (Axum)       ‚îÇ  ‚îÇ (metadata)   ‚îÇ  ‚îÇ tokenizer    ‚îÇ     ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ worker-models (Adapters)                         ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ - QwenModel, Phi3Model, GPTModel                ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ - Architecture detection                         ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ - Forward pass routing                           ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ                         ‚îÇ FFI                               ‚îÇ
‚îÇ                         ‚Üì                                    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚îÇ
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ C++ CUDA LAYER (bin/worker-orcd/cuda/)                      ‚îÇ
‚îÇ                                                              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ FFI Interface (src/ffi.cpp)                      ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ - cuda_init(), cuda_load_model()                ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ - cuda_inference_start(), cuda_next_token()     ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                         ‚îÇ                                    ‚îÇ
‚îÇ                         ‚Üì                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ Model Loading (src/model/)                       ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ - gpt_weights.cpp (GGUF ‚Üí VRAM)                 ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ - gpt_model.cpp (Model structure)               ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                         ‚îÇ                                    ‚îÇ
‚îÇ                         ‚Üì                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ Inference (src/inference_impl.cpp)               ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ - Transformer layers                             ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ - KV cache management                            ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ                         ‚îÇ                                    ‚îÇ
‚îÇ                         ‚Üì                                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ CUDA Kernels (kernels/)                          ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ - attention.cu, rope.cu, rmsnorm.cu, etc.       ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## The Problem

**Our V2 stories focus on C++ CUDA layer**, but we ALSO have:
- Rust `worker-models` with `QwenModel`, `Phi3Model`, `GPTModel`
- Rust `AdapterFactory` with architecture detection
- Rust `worker-gguf` with metadata parsing

**This creates duplication**:
- ‚ùå Architecture detection in BOTH Rust and C++
- ‚ùå Config parsing in BOTH Rust and C++
- ‚ùå Model adapters in BOTH Rust and C++

---

## The Solution: Clear Separation of Concerns

### Rust Layer Responsibilities

**Keep in Rust**:
1. ‚úÖ HTTP server (Axum) - stays in Rust
2. ‚úÖ Tokenization (BPE, HuggingFace) - stays in Rust
3. ‚úÖ GGUF metadata parsing - stays in Rust (lightweight, no GPU)
4. ‚úÖ Architecture detection - stays in Rust (uses GGUF metadata)
5. ‚úÖ Sampling logic - stays in Rust (post-inference)

**Remove from Rust** (move to C++ or make thin wrapper):
1. ‚ùå `QwenModel`, `Phi3Model`, `GPTModel` - These are just stubs anyway
2. ‚ùå Forward pass logic - This belongs in C++/CUDA
3. ‚ùå Weight loading - This belongs in C++/CUDA

### C++ CUDA Layer Responsibilities

**Keep in C++**:
1. ‚úÖ CUDA context management
2. ‚úÖ GPU memory allocation
3. ‚úÖ Weight loading to VRAM
4. ‚úÖ Inference execution
5. ‚úÖ KV cache management
6. ‚úÖ CUDA kernels

**Add to C++** (from V2 stories):
1. ‚úÖ Architecture registry (C++ version)
2. ‚úÖ Tensor mapper (C++ version)
3. ‚úÖ Paged KV cache (C++ version)

---

## Updated Integration Flow

### 1. Startup Flow

```rust
// Rust: main.rs
#[tokio::main]
async fn main() -> Result<()> {
    // 1. Parse GGUF metadata (Rust)
    let metadata = worker_gguf::GGUFMetadata::from_file(&model_path)?;
    let arch = metadata.architecture()?;  // "qwen2", "llama", "gpt2"
    
    // 2. Initialize CUDA context (FFI)
    let cuda_ctx = unsafe { cuda_init(gpu_device, &mut error) };
    
    // 3. Load model to VRAM (FFI, passes arch string)
    let cuda_model = unsafe {
        cuda_load_model(
            cuda_ctx,
            model_path.as_ptr(),
            arch.as_ptr(),  // Pass architecture to C++
            &mut error
        )
    };
    
    // 4. Create tokenizer (Rust)
    let tokenizer = worker_tokenizer::Tokenizer::from_gguf(&model_path)?;
    
    // 5. Start HTTP server (Rust)
    let server = worker_http::HttpServer::new(port, create_router(cuda_model, tokenizer)).await?;
    server.run().await?;
    
    Ok(())
}
```

### 2. Inference Flow

```rust
// Rust: HTTP handler
async fn generate_handler(
    State(state): State<AppState>,
    Json(req): Json<GenerateRequest>,
) -> Result<Response, StatusCode> {
    // 1. Tokenize prompt (Rust)
    let token_ids = state.tokenizer.encode(&req.prompt, true)?;
    
    // 2. Start inference (FFI)
    let result = unsafe {
        cuda_inference_start(
            state.cuda_model,
            token_ids.as_ptr(),
            token_ids.len(),
            req.max_tokens,
            req.temperature,
            &mut error
        )
    };
    
    // 3. Stream tokens
    let stream = async_stream::stream! {
        loop {
            // Get next token from CUDA (FFI)
            let token_id = unsafe { cuda_inference_next_token(result, &mut error) };
            if token_id == EOS_TOKEN { break; }
            
            // Decode token (Rust)
            let text = state.tokenizer.decode(&[token_id], false)?;
            
            // Send SSE event (Rust)
            yield Ok(Event::default().data(text));
        }
    };
    
    Ok(Sse::new(stream).into_response())
}
```

### 3. C++ CUDA Implementation (Updated)

```cpp
// cuda/src/ffi.cpp

extern "C" {

CudaModel* cuda_load_model(
    CudaContext* ctx,
    const char* model_path,
    const char* arch_string,  // NEW: Rust passes architecture
    int* error
) {
    try {
        // Parse architecture (C++ version)
        Architecture arch = ArchitectureRegistry::from_string(arch_string);
        
        // Load weights using architecture registry
        auto weights = GPTWeightLoader::load_from_gguf(model_path, arch);
        
        // Create model
        auto model = new CudaModel(ctx, std::move(weights));
        
        *error = 0;
        return model;
    } catch (const std::exception& e) {
        *error = -1;
        return nullptr;
    }
}

} // extern "C"
```

---

## Updated V2 Stories

### GT-052-V2: Architecture Registry + Weight Loading (C++ ONLY)

**Changes**:
- ‚úÖ Implement in C++ (as planned)
- ‚úÖ Rust passes architecture string via FFI
- ‚úÖ C++ uses registry to load weights
- ‚ùå NO Rust model adapters (they're stubs anyway)

**Rust side** (minimal):
```rust
// worker-models stays as thin wrapper
pub struct QwenModel {
    cuda_model: *mut CudaModel,  // Just holds FFI pointer
}

impl QwenModel {
    pub fn load(path: &str) -> Result<Self> {
        let cuda_model = unsafe { cuda_load_model(...) };
        Ok(Self { cuda_model })
    }
}
```

### GT-053-V2: BPE Tokenizer (RUST ONLY)

**Changes**:
- ‚úÖ Already implemented in `worker-tokenizer`
- ‚úÖ No C++ implementation needed
- ‚úÖ Just wire it up in FFI boundary

**No changes needed** - `worker-tokenizer` is already complete!

### GT-054-V2: Paged KV Cache (C++ ONLY)

**Changes**:
- ‚úÖ Implement in C++ (as planned)
- ‚úÖ No Rust involvement
- ‚úÖ Pure CUDA implementation

### GT-056-V2: Wire Inference (FFI INTEGRATION)

**Changes**:
- ‚úÖ Update FFI to pass architecture string
- ‚úÖ Update Rust HTTP handlers
- ‚úÖ Wire tokenizer (Rust) ‚Üí inference (C++) ‚Üí sampling (Rust)

---

## What to Keep from worker-crates

### Keep (Already Working)

1. **`worker-http`** - HTTP server, SSE streaming
2. **`worker-tokenizer`** - BPE, HuggingFace tokenizers
3. **`worker-gguf`** - Metadata parsing (lightweight)
4. **`worker-common`** - Error types, sampling config

### Simplify (Make Thin Wrappers)

1. **`worker-models`** - Just hold FFI pointers, no logic
   ```rust
   pub struct QwenModel {
       cuda_model: *mut CudaModel,
   }
   ```

2. **`AdapterFactory`** - Just parse metadata and call FFI
   ```rust
   impl AdapterFactory {
       pub fn from_gguf(path: &str) -> Result<LlamaModelAdapter> {
           let metadata = GGUFMetadata::from_file(path)?;
           let arch = metadata.architecture()?;
           let cuda_model = unsafe { cuda_load_model(path, arch) };
           Ok(LlamaModelAdapter::new(cuda_model))
       }
   }
   ```

### Remove (Duplicate Logic)

1. ‚ùå Forward pass implementations in Rust (stubs anyway)
2. ‚ùå Weight loading in Rust (belongs in C++)
3. ‚ùå Config parsing in Rust (C++ does this from GGUF)

---

## Implementation Priority

### Phase 1: C++ CUDA Layer (GT-052, GT-054)
1. Implement ArchitectureRegistry in C++
2. Implement PagedKVCache in C++
3. Update FFI to accept architecture string

### Phase 2: Rust Integration (GT-056)
1. Update FFI bindings
2. Wire tokenizer ‚Üí CUDA ‚Üí sampling
3. Update HTTP handlers

### Phase 3: Cleanup (Post-M0)
1. Simplify `worker-models` to thin wrappers
2. Remove duplicate logic
3. Document FFI boundary

---

## Decision

**Proceed with V2 stories as planned**, but:

1. ‚úÖ **Implement in C++** - Architecture registry, paged KV cache
2. ‚úÖ **Keep Rust layer thin** - HTTP, tokenization, metadata parsing
3. ‚úÖ **Clear FFI boundary** - Rust passes arch string, C++ does inference
4. ‚úÖ **No duplication** - Logic lives in ONE place (C++ for compute, Rust for I/O)

**Benefit**: Clean separation, no duplicate logic, leverages strengths of both languages.

---

**Created by**: Project Management Team üìã  
**Date**: 2025-10-05  
**Status**: Architecture clarified  
**Next**: Proceed with V2 C++ implementation

---
Reviewed by Testing Team üîç
