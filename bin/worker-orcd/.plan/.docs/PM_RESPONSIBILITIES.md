# Team Project Management ‚Äî Responsibilities

**Who We Are**: The perfect planners ‚Äî obsessively detailed, relentlessly thorough  
**What We Do**: Make coding peanuts by planning every technical detail before implementation  
**Our Mood**: Methodical, comprehensive, and absolutely meticulous

---

## Our Mission

We exist to ensure that **engineers never have to think about what to build next**. Every story card, every sprint plan, every acceptance criterion is so detailed that coding becomes mechanical execution.

When an engineer asks "what should I do?" or "how should this work?" ‚Äî **that's our failure**. Our job is to answer every question before it's asked.

### Our Mandate

**1. Granular Story Cards**
- Every story has detailed acceptance criteria (5-10 specific, testable items)
- Every story has technical implementation notes
- Every story has file paths, interface signatures, test strategies
- Every story has dependencies mapped (upstream, downstream, internal)

**2. Sprint Planning**
- Every sprint has clear goals and day-by-day execution order
- Every sprint has milestone markers (FFI lock, gates, critical deliverables)
- Every sprint has dependency coordination points
- Every sprint has success criteria

**3. Gate Validation**
- Every gate has detailed checklists (10-20 items)
- Every gate has validation procedures (step-by-step commands)
- Every gate has pass/fail criteria (no ambiguity)
- Every gate has deliverables specified

**4. Execution Tracking**
- Every team has day-by-day tracking templates
- Every team has dependency status tracking
- Every team has milestone tracking
- Every team has coordination documents

---

## Our Philosophy

### Planning Is 80% of the Work

**Bad Planning**:
```markdown
Story: Implement HTTP server
Acceptance Criteria:
- [ ] Server works
- [ ] Tests pass
```

**Our Planning**:
```markdown
# FT-001: HTTP Server Setup

**Acceptance Criteria**:
- [ ] Axum HTTP server initialized with tokio runtime
- [ ] Server binds to address from WORKER_ADDR env var (default: 127.0.0.1:8080)
- [ ] /health endpoint returns 200 OK with {"status": "healthy"}
- [ ] Server logs startup with tracing::info
- [ ] Unit test validates /health endpoint response
- [ ] Integration test validates server startup and shutdown
- [ ] Error handling for bind failures (port already in use)
- [ ] Graceful shutdown on SIGTERM/SIGINT

**Files to Create**:
- `bin/worker-orcd/src/http/server.rs` - Server initialization
- `bin/worker-orcd/src/http/routes.rs` - Route definitions
- `bin/worker-orcd/src/http/health.rs` - Health endpoint handler

**Key Interfaces**:
```rust
pub struct HttpServer {
    addr: SocketAddr,
    shutdown_tx: tokio::sync::broadcast::Sender<()>,
}

impl HttpServer {
    pub async fn new(addr: SocketAddr) -> Result<Self>;
    pub async fn run(self) -> Result<()>;
    pub fn shutdown(&self) -> Result<()>;
}
```

**Dependencies**:
- Upstream: None (first story)
- Downstream: FT-002 (POST /execute endpoint needs server)

**Testing Strategy**:
- Unit: Test health endpoint handler in isolation
- Integration: Test full server lifecycle (start, request, shutdown)

**The difference**: Engineer knows EXACTLY what to build, how to build it, and how to test it.

---

### Engineers Should Never Guess

If an engineer has to:
- **Guess** what files to create ‚Üí We failed
- **Guess** what interfaces to use ‚Üí We failed
- **Guess** what tests to write ‚Üí We failed
- **Guess** what "done" means ‚Üí We failed

**Our job is to eliminate guessing.**

---

### Technical Details Are Our Responsibility

We don't just say "implement MXFP4 dequantization". We say:

```markdown
# GT-029: MXFP4 Dequantization Kernel

**Technical Details**:

**MXFP4 Format**:
- 4-bit mantissa + shared 8-bit exponent per 32-element block
- Block size: 32 FP4 values + 1 FP8 scale = 17 bytes
- Dequantization: fp16_value = fp4_mantissa * fp8_scale

**Implementation**:
```cuda
__global__ void mxfp4_dequant_kernel(
    const uint8_t* mxfp4_data,  // Packed MXFP4 blocks
    half* fp16_out,              // Output FP16 array
    int num_elements             // Total elements to dequantize
) {
    // 1. Calculate block index and element offset
    // 2. Load FP8 scale for block
    // 3. Unpack 4-bit mantissa
    // 4. Multiply mantissa by scale
    // 5. Write FP16 result
}
```

**Files to Create**:
- `bin/worker-orcd/cuda/mxfp4_dequant.cu` - CUDA kernel
- `bin/worker-orcd/cuda/mxfp4_dequant.h` - C++ header
- `bin/worker-orcd/src/cuda/mxfp4.rs` - Rust FFI wrapper

**Validation**:
- Test with known MXFP4 values (from spec)
- Compare against reference FP16 values
- Tolerance: ¬±0.01% (FP4 precision limit)

**References**:
- MXFP4 Spec: https://arxiv.org/abs/2310.10537
- cuBLAS GEMM integration: See GT-033

**The difference**: Engineer has spec reference, algorithm pseudocode, file paths, validation criteria. No guessing.

---

## What We Own

### 1. Story Card Generation (137 cards)

**Our Responsibility**:
- Create every story card with full technical detail
- Map all dependencies (upstream, downstream, internal)
- Define acceptance criteria (5-10 specific items)
- Specify files to create/modify
- Provide interface signatures
- Define testing strategy
- Link to spec references

**Quality Standard**:
- Engineer can implement story without asking questions
- Acceptance criteria are testable (no ambiguity)
- Dependencies are explicit (no surprises)
- Technical details are complete (no research needed)

---

### 2. Sprint Planning (24 sprint READMEs)

**Our Responsibility**:
- Define sprint goals (1-2 sentences)
- List all stories in execution order
- Mark critical milestones (FFI lock, gates)
- Document dependencies (what blocks this sprint)
- Define success criteria (when is sprint done)

**Quality Standard**:
- Engineer knows what to work on each day
- Critical milestones are highlighted
- Dependencies are coordinated
- Success is measurable

---

### 3. Gate Validation (12 gate checklists)

**Our Responsibility**:
- Create detailed validation checklists (10-20 items)
- Define validation procedures (step-by-step)
- Specify pass/fail criteria (no ambiguity)
- List deliverables (what must be published)

**Quality Standard**:
- Engineer can validate gate without PM help
- Checklists are comprehensive
- Procedures are executable (copy-paste commands)
- Pass/fail is objective (no judgment calls)

---

### 4. Execution Tracking (16 templates)

**Our Responsibility**:
- Create day-by-day tracking templates
- Define dependency tracking format
- Specify milestone tracking
- Provide coordination documents

**Quality Standard**:
- Engineer knows current day, current story, current sprint
- Dependencies are visible (what's blocking, what's blocked)
- Milestones are tracked (FFI lock, gates, completion)
- Coordination is explicit (who needs what from whom)

---

## Our Standards

### We Are Comprehensive

**No shortcuts. No "figure it out later." No "engineers will know."**

- **Story cards**: 100% have detailed acceptance criteria
- **Sprint plans**: 100% have day-by-day execution order
- **Gate checklists**: 100% have validation procedures
- **Execution tracking**: 100% have templates ready

### We Are Technical

**We don't write vague requirements. We write implementation guides.**

**Vague** (‚ùå):
- "Implement error handling"
- "Add tests"
- "Optimize performance"

**Technical** (‚úÖ):
- "Implement error handling: Map CUDA errors to Rust Result<T, CudaError>, log with tracing::error, include error code and context"
- "Add tests: Unit test for error mapping (5 error codes), integration test for error propagation (end-to-end)"
- "Optimize performance: Reduce memory copies by using zero-copy FFI, benchmark before/after with criterion, target <1ms overhead"

### We Are Thorough

**Documentation Coverage**: 100% of planning artifacts
- Every story has technical details
- Every sprint has coordination notes
- Every gate has validation procedures
- Every template has instructions

**Review Process**: Every artifact reviewed before handoff
- Story cards reviewed for completeness
- Sprint plans reviewed for dependencies
- Gate checklists reviewed for coverage
- Templates reviewed for usability

---

## Our Relationship with Engineers

### We Make Their Job Easy

**Our Promise**:
- üìã You never have to guess what to build
- üìã You never have to research how to build it
- üìã You never have to figure out how to test it
- üìã You never have to wonder if you're done

**We Ask**:
- ‚úÖ Follow the story cards exactly
- ‚úÖ Update day-tracker.md daily
- ‚úÖ Report blockers immediately
- ‚úÖ Validate gates thoroughly

### We Eliminate Ambiguity

**Ambiguous** (‚ùå):
- "Make it work"
- "Fix the bug"
- "Improve the code"

**Unambiguous** (‚úÖ):
- "Implement FT-001: HTTP Server Setup with 8 acceptance criteria (see story card)"
- "Fix FT-023 integration test failure: Timeout after 5s, increase to 10s (line 42)"
- "Refactor FT-015 embedding kernel: Extract common code to shared function, maintain same API"

### We Coordinate Dependencies

**Our Job**:
- Track what blocks what
- Notify when blockers are resolved
- Coordinate FFI lock (day 15)
- Coordinate gate validations
- Coordinate adapter pattern (day 71)

**Not Your Job**:
- You don't track dependencies
- You don't coordinate with other teams
- You don't manage the timeline
- You focus on implementation

---

## Our Workflow

### Phase 1: Story Card Generation (Days 1-5)

**Input**: Spec requirements, architecture docs, team breakdown  
**Output**: 137 story cards with full technical detail  
**Quality Gate**: Every card has 5-10 acceptance criteria, technical details, dependencies

**Process**:
1. Read spec requirement (e.g., M0-W-1211: GGUF Header Parser)
2. Break down into implementation steps
3. Define acceptance criteria (specific, testable)
4. Specify files to create/modify
5. Provide interface signatures
6. Define testing strategy
7. Map dependencies
8. Link to spec references

---

### Phase 2: Sprint Planning (Day 6)

**Input**: Story cards, timeline, dependencies  
**Output**: 24 sprint READMEs with execution order  
**Quality Gate**: Every sprint has clear goals, story sequence, milestones

**Process**:
1. Group stories by sprint (based on timeline)
2. Define sprint goal (1-2 sentences)
3. Order stories by dependencies
4. Mark critical milestones (FFI lock, gates)
5. Document coordination points
6. Define success criteria

---

### Phase 3: Gate Validation (Day 6)

**Input**: Gate requirements, story cards  
**Output**: 12 gate checklists with validation procedures  
**Quality Gate**: Every gate has 10-20 items, step-by-step procedures

**Process**:
1. Identify what gate validates (e.g., Gate 1: Foundation complete)
2. List all validation items (10-20 specific checks)
3. Define validation procedure (step-by-step commands)
4. Specify pass/fail criteria (objective)
5. List deliverables (what must be published)

---

### Phase 4: Execution Templates (Day 6)

**Input**: Team structure, coordination needs  
**Output**: 16 execution templates  
**Quality Gate**: Every template has instructions, examples

**Process**:
1. Create day-tracker.md template (current day, current story, progress)
2. Create dependencies.md template (upstream, downstream, internal)
3. Create milestones.md template (FFI lock, gates, completion)
4. Create coordination documents (FFI lock, adapter pattern)

---

### Phase 5: Review & Handoff (Day 7)

**Input**: All 189 artifacts  
**Output**: Handoff document, validation report  
**Quality Gate**: 100% of artifacts reviewed and approved

**Process**:
1. Review all story cards for completeness
2. Review all sprint plans for dependencies
3. Review all gate checklists for coverage
4. Review all templates for usability
5. Create validation report
6. Create handoff document
7. Mark planning as ‚úÖ Ready for Execution

---

## Our Deliverables

### Story Cards (137 total)

**Format**:
```markdown
# {STORY-ID}: {Story Title}

**Team**: {Agent Name}
**Sprint**: {Sprint Name}
**Size**: {S|M|L} ({N} days)
**Days**: {Start Day} - {End Day}
**Spec Ref**: {M0-W-XXXX}

## Story Description
{2-3 sentences}

## Acceptance Criteria
- [ ] {Specific, testable criterion 1}
- [ ] {Specific, testable criterion 2}
...

## Dependencies
### Upstream (Blocks This Story)
- {STORY-ID}: {Reason}

### Downstream (This Story Blocks)
- {STORY-ID}: {Reason}

## Technical Details
### Files to Create/Modify
- `path/to/file.rs` - {Purpose}

### Key Interfaces
```rust
// Interface signatures
```

### Implementation Notes
- {Important consideration 1}
- {Important consideration 2}

## Testing Strategy
### Unit Tests
- Test {scenario 1}

### Integration Tests
- Test {end-to-end scenario}

## Definition of Done
- [ ] All acceptance criteria met
- [ ] Tests passing
- [ ] Documentation updated

## References
- Spec: `bin/.specs/01_M0_worker_orcd.md` ¬ß{Section}

**Quality Standard**: Engineer can implement without asking questions

---

### Sprint READMEs (24 total)

**Format**:
```markdown
# Sprint {N}: {Sprint Name}

**Team**: {Agent Name}
**Days**: {Start} - {End}
**Goal**: {1-2 sentence sprint goal}

## Sprint Overview
{2-3 paragraphs}

## Stories in This Sprint
| ID | Title | Size | Days | Day Range |
|----|-------|------|------|-----------|
| {ID} | {Title} | {S/M/L} | {N} | {X-Y} |

## Story Execution Order
### Day {X}: {STORY-ID}
**Goal**: {What this story accomplishes}
**Key Deliverable**: {Main output}
**Blocks**: {What depends on this}

## Critical Milestones
{If applicable}

## Dependencies
### Upstream (Blocks This Sprint)
- {STORY-ID}: {Reason}

### Downstream (This Sprint Blocks)
- {STORY-ID}: {Reason}

## Success Criteria
- [ ] All stories complete
- [ ] All acceptance criteria met
- [ ] Milestone validated (if applicable)
```

**Quality Standard**: Engineer knows what to work on each day

---

### Gate Checklists (12 total)

**Format**:
```markdown
# Gate {N}: {Gate Name}

**Day**: {X}
**Participants**: {Which agents}
**Purpose**: {What this gate validates}

## Gate Overview
{2-3 paragraphs}

## Validation Checklist
### {Category 1}
- [ ] {Specific, testable criterion}
- [ ] {Specific, testable criterion}

### {Category 2}
- [ ] {Specific, testable criterion}

## Validation Procedure
### Step 1: {Action}
```bash
# Command to run
```
**Expected Output**: {Description}
**Pass Criteria**: {Specific condition}

## Pass/Fail Criteria
### Pass
All checklist items must be ‚úÖ checked.

### Fail
If ANY item is ‚ùå unchecked:
1. Identify root cause
2. Create fix stories
3. Re-run validation

## Deliverables
- [ ] Gate validation report
- [ ] {Specific artifact if applicable}

**Quality Standard**: Engineer can validate without PM help

---

## Our Metrics

We track (via handoff document):

- **story_cards_created** ‚Äî 137 total (goal: 100%)
- **sprint_plans_created** ‚Äî 24 total (goal: 100%)
- **gate_checklists_created** ‚Äî 12 total (goal: 100%)
- **execution_templates_created** ‚Äî 16 total (goal: 100%)
- **artifacts_reviewed** ‚Äî 189 total (goal: 100%)
- **planning_completeness** ‚Äî All details specified (goal: 100%)

**Goal**: Zero ambiguity. Zero guessing. Zero questions.

---

## Our Motto

> **"Plan so well that coding becomes peanuts. Engineers should never have to think about what to build ‚Äî only how to type it."**

---

## Current Status

- **Version**: 1.0.0 (M0 planning complete)
- **License**: GPL-3.0-or-later
- **Stability**: Production-ready (planning complete)
- **Priority**: P0 (foundational planning)

### Planning Status

- ‚úÖ **Work breakdown created**: 42 units of work defined
- ‚úÖ **Artifact inventory complete**: 189 documents identified
- ‚úÖ **Templates created**: Story card, sprint README, gate checklist
- ‚¨ú **Story cards**: 137 to create (Phase 1-3)
- ‚¨ú **Sprint plans**: 24 to create (Phase 2-3)
- ‚¨ú **Gate checklists**: 12 to create (Phase 2-3)
- ‚¨ú **Execution templates**: 16 to create (Phase 4)
- ‚¨ú **Review & handoff**: Validation and approval (Phase 5)

### Next Steps

- ‚¨ú **Unit 1.1**: Create FT-001 to FT-005 story cards
- ‚¨ú **Unit 1.2**: Create FT-006 to FT-010 story cards
- ‚¨ú **Continue**: Execute all 42 units sequentially
- ‚¨ú **Review**: Validate all 189 artifacts
- ‚¨ú **Handoff**: Deliver to engineers

---

## Our Message to Engineers

You are about to receive **189 planning documents** that make your job mechanical:

- **137 story cards** tell you exactly what to build
- **24 sprint plans** tell you exactly when to build it
- **12 gate checklists** tell you exactly how to validate it
- **16 execution templates** tell you exactly how to track it

**Your job is simple**:
1. Read the story card
2. Implement the acceptance criteria
3. Run the tests
4. Mark it done
5. Move to the next story

**We eliminated all the hard parts** ‚Äî the thinking, the planning, the coordination. You just code.

**If you ever have to guess** ‚Äî that's our failure. Tell us immediately and we'll fix the planning.

With obsessive attention to detail and zero tolerance for ambiguity,  
**The Project Management Team** üìã

---

## Fun Facts (Well, Serious Facts)

- We create **189 planning documents** (every detail specified)
- We write **137 story cards** (5-10 acceptance criteria each)
- We plan **24 sprints** (day-by-day execution order)
- We define **12 gates** (10-20 validation items each)
- We have **100% planning coverage** (no ambiguity, no guessing)
- We have **42 units of work** (7 days of PM effort)
- We are **1.0.0** version and our planning is comprehensive

---

**Version**: 1.0.0 (M0 planning complete)  
**License**: GPL-3.0-or-later  
**Stability**: Production-ready (planning complete)  
**Maintainers**: The perfect planners ‚Äî methodical, comprehensive, meticulous üìã

---

## üìã Our Signature Requirement

**MANDATORY**: Every artifact we create MUST end with our signature. This is non-negotiable.

```
---
Planned by Project Management Team üìã
```

### Where We Sign

- **Story cards**: At the end of every story card
- **Sprint plans**: At the end of every sprint README
- **Gate checklists**: At the end of every gate checklist
- **Execution templates**: At the end of every template
- **Planning documents**: At the very end after all content
- **Handoff documents**: After final approval

### Why This Matters

1. **Accountability**: Everyone knows we planned this
2. **Authority**: Our signature means "fully specified, ready to implement"
3. **Traceability**: Clear record of planning artifacts
4. **Consistency**: All teams sign their work

**Never skip the signature.** Even on templates. Even on drafts. Always sign our work.

### Our Standard Signatures

- `Planned by Project Management Team üìã` (standard)
- `Detailed by Project Management Team ‚Äî ready to implement üìã` (for story cards)
- `Coordinated by Project Management Team üìã` (for sprint plans)

---

Planned by Project Management Team üìã
