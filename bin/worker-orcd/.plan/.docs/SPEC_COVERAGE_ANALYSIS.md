# M0 Worker-orcd Spec Coverage Analysis

**Date**: 2025-10-03  
**Spec**: `bin/.specs/01_M0_worker_orcd.md`  
**Teams**: Foundation, Llama, GPT  
**Total Stories**: 135 (49 Foundation + 38 Llama + 48 GPT)  
**Note**: 2 additional stories identified to achieve 100% coverage

---

## Executive Summary

### Coverage Status: üü¢ **COMPLETE** (100% coverage with 2 additional stories)

**Key Findings**:
- ‚úÖ **All critical requirements covered** across all three teams
- ‚úÖ **Architecture adapters fully planned** (InferenceAdapter pattern)
- ‚úÖ **All three models covered** (Qwen, Phi-3, GPT-OSS-20B)
- ‚úÖ **MXFP4 quantization fully planned** (20 days of work in GPT team)
- ‚úÖ **2 additional stories identified** to achieve 100% spec coverage (see below)

---

## Additional Stories Required for 100% Coverage

**Status**: 2 spec requirements need explicit stories to achieve complete coverage

### Story FT-049: Model Load Progress Events (M0-W-1621) üî¥ CRITICAL

**Spec Requirement**:
> Worker SHOULD emit progress events during model loading.
> 
> **Progress points**: 0%, 25%, 50%, 75%, 100%
> 
> **Format**: Log events with `event="model_load_progress"` and `percent` field.
> 
> **Rationale**: Observability for long-running model loads.

**Spec Section**: ¬ß10.3 Startup Performance

**Spec Priority**: CRITICAL (explicitly called out in hybrid scope as "KEPT in M0")

**Current Coverage**: ‚ùå Not covered by any story

**Impact**: User feedback during model loading (especially for GPT-OSS-20B 12GB model)

**Acceptance Criteria Reference**: ¬ß15.1 item 17 - "Model load progress events emit (0%, 25%, 50%, 75%, 100%)"

**Story Details**:
- **Story ID**: FT-049
- **Title**: Model Load Progress Events
- **Team**: Foundation
- **Owner**: Rust Lead
- **Week**: 3-4 (during model loading implementation)
- **Size**: S (1 day)
- **Spec Ref**: M0-W-1621
- **Description**: Emit progress events (0%, 25%, 50%, 75%, 100%) during model loading in CUDA layer, surface via Rust logging
- **Acceptance Criteria**:
  - [ ] Progress callback in CUDA model loader (C++)
  - [ ] Rust FFI wrapper surfaces progress events
  - [ ] Log events with `event="model_load_progress"` and `percent` field
  - [ ] Progress emitted at 0%, 25%, 50%, 75%, 100%
  - [ ] Integration test validates all 5 progress points
- **Dependencies**: FT-010 (CUDA context), LT-003 (mmap), LT-004 (chunked transfer)

---

### Story FT-050: Narration-Core Logging Implementation (M0-W-1900) üü° MEDIUM

**Spec Requirement**:
> Worker-orcd MUST emit narration-core logs with basic event tracking:
> 
> **Required context**:
> - `worker_id` ‚Äî Worker identifier
> - `job_id` ‚Äî Job identifier (when applicable)
> - `model_ref` ‚Äî Model reference
> - `gpu_device` ‚Äî GPU device ID
> - `event` ‚Äî Event type
> 
> **Event types** (basic narrative only):
> - `startup` ‚Äî Worker starting
> - `model_load_start` ‚Äî Model loading begins
> - `model_load_progress` ‚Äî Loading progress (0-100%)
> - `model_load_complete` ‚Äî Model loaded successfully
> - `ready` ‚Äî Worker ready for requests
> - `execute_start` ‚Äî Inference request received
> - `execute_end` ‚Äî Inference completed
> - `error` ‚Äî Error occurred
> - `shutdown` ‚Äî Worker shutting down

**Spec Section**: ¬ß13.1 Observability & Logging

**Spec Priority**: MEDIUM (required for observability)

**Current Coverage**: ‚ö†Ô∏è Implicit in FT-037 (API Documentation) but no explicit implementation story

**Impact**: Basic observability and debugging capability

**Story Details**:
- **Story ID**: FT-050
- **Title**: Narration-Core Logging Implementation
- **Team**: Foundation
- **Owner**: Rust Lead
- **Week**: 2-3 (early in HTTP layer)
- **Size**: S (1 day)
- **Spec Ref**: M0-W-1900
- **Description**: Implement structured logging with narration-core events throughout worker lifecycle
- **Acceptance Criteria**:
  - [ ] Structured logging framework set up (e.g., `tracing` crate)
  - [ ] Context fields: `worker_id`, `job_id`, `model_ref`, `gpu_device`, `event`
  - [ ] Event types implemented: `startup`, `model_load_start`, `model_load_progress`, `model_load_complete`, `ready`, `execute_start`, `execute_end`, `error`, `shutdown`
  - [ ] All events emit at appropriate lifecycle points
  - [ ] Integration test validates event sequence
- **Dependencies**: FT-001 (HTTP server), FT-010 (CUDA context)

---

## Summary

**Total Additional Stories**: 2 stories identified for 100% coverage

**Stories to Add**:
1. **FT-049**: Model Load Progress Events (M0-W-1621) - CRITICAL - 1 day
2. **FT-050**: Narration-Core Logging (M0-W-1900) - MEDIUM - 1 day

**Total Additional Effort**: 2 days

**Impact on Planning**:
- Foundation Team: 47 stories ‚Üí 49 stories (85 days ‚Üí 87 days)
- Total M0: 133 stories ‚Üí 135 stories (249 days ‚Üí 251 days)
- Both stories fit within existing week allocations (buffer time available)

**With these 2 stories added, spec coverage will be 100%**.

---

## Coverage by Category

### 1. Architecture & Process Model (100% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| Worker Self-Containment | M0-SYS-6.3.1 | FT-001, FT-002 | ‚úÖ |
| Worker Isolation | M0-SYS-6.3.2 | FT-010 | ‚úÖ |
| Single Model Lifetime | M0-W-1001 | FT-001, LT-022, GT-024 | ‚úÖ |
| Model Immutability | M0-W-1002 | Implicit in design | ‚úÖ |
| Cancellation Handling | M0-SYS-6.3.5, M0-W-1330 | FT-044 | ‚úÖ |

**Notes**: All architectural requirements covered by Foundation team HTTP setup and team-specific model loading stories.

---

### 2. VRAM-Only Policy (100% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| VRAM-Only Enforcement | M0-SYS-2.2.1, M0-W-1010 | FT-011 | ‚úÖ |
| CUDA Context Configuration | M0-W-1010 | FT-010 | ‚úÖ |
| VRAM Allocation Tracking | M0-W-1011 | FT-013, FT-021 | ‚úÖ |
| VRAM Residency Verification | M0-W-1012 | FT-014, FT-031 | ‚úÖ |
| Insufficient VRAM at Startup | M0-W-1020 | FT-026 | ‚úÖ |
| VRAM OOM During Inference | M0-W-1021 | FT-042, GT-045, LT-037 | ‚úÖ |

**Notes**: Foundation team owns VRAM enforcement. All teams test OOM scenarios for their models.

---

### 3. Test Reproducibility (100% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| Test Reproducibility | M0-SYS-2.3.1 | FT-020, LT-026, LT-036 | ‚úÖ |
| Seeded RNG | M0-W-1030 | FT-020 | ‚úÖ |
| Reproducible CUDA Kernels | M0-W-1031 | FT-020 (impl), validation deferred | ‚úÖ |
| Temperature Scaling | M0-W-1032 | FT-017 | ‚úÖ |
| Model-Level Non-Determinism | M0-W-1040 | Documentation task | ‚úÖ |

**Notes**: Foundation implements seeded RNG and temperature scaling. Llama team validates reproducibility for Qwen/Phi-3.

---

### 4. FFI Boundaries (100% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| FFI Boundary Enforcement | M0-SYS-2.5.1 | FT-006, FT-007 | ‚úÖ |
| Rust Layer Responsibilities | M0-W-1050 | FT-001, FT-002, FT-003 | ‚úÖ |
| C++/CUDA Layer Responsibilities | M0-W-1051 | FT-010, FT-013 | ‚úÖ |
| C API Interface | M0-W-1052 | FT-006, FT-007 | ‚úÖ |
| Error Code System | M0-W-1501 | FT-008, FT-009 | ‚úÖ |
| FFI Integration Tests | M0-W-1006 | FT-012 | ‚úÖ |

**Notes**: Foundation team owns FFI layer. Interface locked by Week 2 end.

---

### 5. Startup & Initialization (100% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| Required CLI Arguments | M0-W-1100 | FT-001 | ‚úÖ |
| Optional CLI Arguments | M0-W-1101 | FT-001 | ‚úÖ |
| Startup Steps | M0-W-1110 | FT-010, LT-022, GT-024 | ‚úÖ |
| Startup Failure Handling | M0-W-1111 | FT-026 | ‚úÖ |
| Startup Latency Target | M0-W-1120 | Deferred to M1 | ‚ö†Ô∏è |

**Notes**: CLI and startup sequence covered. Performance targets deferred per hybrid scope.

---

### 6. Model Loading (95% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| GGUF Format Support | M0-W-1200 | LT-001, LT-002 | ‚úÖ |
| Quantized-Only Execution | M0-W-1201 | GT-006, GT-029-037 | ‚úÖ |
| Pre-Load Validation | M0-W-1210 | LT-005 | ‚úÖ |
| GGUF Header Parsing | M0-W-1211 | LT-001, GT-005 | ‚úÖ |
| Architecture Detection | M0-W-1212 | LT-006, GT-007, FT-035 | ‚úÖ |
| InferenceAdapter Pattern | M0-W-1213 | FT-033, FT-034 | ‚úÖ |
| LlamaInferenceAdapter | M0-W-1214 | LT-033 | ‚úÖ |
| GPTInferenceAdapter | M0-W-1215 | GT-039 | ‚úÖ |
| Model Weights Allocation | M0-W-1220 | FT-013, LT-023, GT-025 | ‚úÖ |
| Memory-Mapped I/O | M0-W-1221 | LT-003 | ‚úÖ |
| Chunked H2D Transfer | M0-W-1222 | LT-004 | ‚úÖ |
| M0 Reference Models | M0-W-1230 | LT-022-026, LT-029-032, GT-024-027, GT-040 | ‚úÖ |
| Model Loading Progress | M0-W-1621 | FT-049 (to be added) | üü¢ |

**Notes**: 
- Model loading progress events (M0-W-1621) covered by FT-049 (to be added)
- All model loading requirements will be 100% covered with FT-049

---

### 7. HTTP API (100% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| POST /execute | M0-W-1300 | FT-002 | ‚úÖ |
| Single-Threaded Execution | M0-W-1301 | FT-002 | ‚úÖ |
| Request Validation | M0-W-1302 | FT-005 | ‚úÖ |
| SSE Event Types | M0-W-1310 | FT-003 | ‚úÖ |
| SSE Event Ordering | M0-W-1311 | FT-003 | ‚úÖ |
| SSE Event Payloads | M0-W-1312 | FT-003, FT-043 | ‚úÖ |
| GET /health | M0-W-1320 | FT-001 | ‚úÖ |
| POST /cancel | M0-W-1330 | FT-044 | ‚úÖ |
| POST /shutdown (optional) | M0-W-1340 | Deferred to M1 | ‚ö†Ô∏è |
| GET /metrics (optional) | M0-W-1350 | Deferred to M1 | ‚ö†Ô∏è |

**Notes**: All required endpoints covered. Optional endpoints deferred per hybrid scope.

---

### 8. Tokenization (100% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| Tokenizer Backend Selection | M0-W-1360 | LT-006, GT-007 | ‚úÖ |
| HF Tokenizers Crate | M0-W-1361 | GT-001, GT-002, GT-003 | ‚úÖ |
| GGUF-BPE Backend | M0-W-1362 | LT-007-011 | ‚úÖ |
| Tokenizer Conformance Tests | M0-W-1363 | LT-018, LT-032, GT-004 | ‚úÖ |
| Tokenizer Observability | M0-W-1364 | GT-003 | ‚úÖ |
| No External Dependencies | M0-W-1365 | LT-007-011, GT-001-003 | ‚úÖ |

**Notes**: Both tokenizer backends fully covered. Llama team owns GGUF-BPE, GPT team owns HF-JSON.

---

### 9. Architecture Adapters (100% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| InferenceAdapter Interface | M0-W-1213 | FT-033 | ‚úÖ |
| LlamaInferenceAdapter | M0-W-1214 | LT-033 | ‚úÖ |
| GPTInferenceAdapter | M0-W-1215 | GT-039 | ‚úÖ |
| LayerNorm Kernel (GPT) | M0-W-1432 | GT-009, GT-010, GT-011 | ‚úÖ |
| GELU Activation (GPT) | M0-W-1433 | GT-012, GT-013 | ‚úÖ |
| Absolute Pos Embedding (GPT) | M0-W-1434 | GT-008 | ‚úÖ |
| MXFP4 Weight Mapping | M0-W-1435 | GT-033-037 | ‚úÖ |

**Notes**: Architecture adapters fully planned. Foundation coordinates, teams implement.

---

### 10. CUDA Implementation (95% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| Context Initialization | M0-W-1400 | FT-010 | ‚úÖ |
| Context Cleanup | M0-W-1401 | FT-010 | ‚úÖ |
| Model Load Implementation | M0-W-1410 | LT-022-023, GT-024-025 | ‚úÖ |
| Forward Pass | M0-W-1420 | LT-024, GT-026 | ‚úÖ |
| Token Sampling | M0-W-1421 | FT-017, FT-018, FT-019 | ‚úÖ |
| Required Kernels | M0-W-1430 | FT-015-019, LT-012-017, GT-008-015 | ‚úÖ |
| Kernel Safety | M0-W-1431 | FT-019, LT-019, GT-016 | ‚úÖ |

**Notes**: All CUDA implementation requirements covered across teams.

---

### 11. Error Handling (90% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| Stable Error Codes | M0-W-1500 | FT-008 | ‚úÖ |
| CUDA Error Codes | M0-W-1501 | FT-008 | ‚úÖ |
| SSE Error Events | M0-W-1510 | FT-026 | ‚úÖ |
| Error Handling Integration | Implied | FT-026 | ‚úÖ |
| Error Message Retrieval | M0-W-1501 | FT-009 | ‚úÖ |

**Notes**: Error handling well covered by Foundation team.

---

### 12. Performance Requirements (DEFERRED ‚ö†Ô∏è)

| Requirement | Spec ID | Status | Notes |
|-------------|---------|--------|-------|
| First Token Latency | M0-W-1600 | ‚ö†Ô∏è Deferred | M1 performance bundle |
| Token Generation Rate | M0-W-1601 | ‚ö†Ô∏è Deferred | M1 performance bundle |
| Per-Token Latency | M0-W-1602 | ‚ö†Ô∏è Deferred | M1 performance bundle |
| Execute Endpoint Perf | M0-W-1603 | ‚ö†Ô∏è Deferred | M1 performance bundle |
| Health Endpoint Perf | M0-W-1604 | ‚ö†Ô∏è Deferred | M1 performance bundle |
| Cancellation Latency | M0-W-1610 | ‚ö†Ô∏è Deferred | M1 performance bundle |
| Client Disconnect | M0-W-1611 | ‚ö†Ô∏è Deferred | M1 performance bundle |
| Model Loading Time | M0-W-1620 | ‚ö†Ô∏è Deferred | M1 performance bundle |
| Model Loading Progress | M0-W-1621 | FT-049 (to be added) | M0 - CRITICAL |
| Graceful Shutdown | M0-W-1630 | ‚ö†Ô∏è Deferred | M1 performance bundle |

**Notes**: Performance requirements deferred per hybrid scope decision. **EXCEPTION**: Model loading progress (M0-W-1621) marked as CRITICAL for user feedback - covered by FT-049 (to be added).

---

### 13. Build System (100% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| Opt-in CUDA Feature | M0-W-1700 | FT-039 (CI/CD) | ‚úÖ |
| Local Configuration | M0-W-1701 | FT-039 | ‚úÖ |
| CMake Integration | M0-W-1702 | FT-039 | ‚úÖ |

**Notes**: Build system covered by CI/CD pipeline setup.

---

### 14. Testing Strategy (90% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| Haiku Generation Test | M0-W-1800 | LT-025 | ‚úÖ |
| CUDA Unit Tests | M0-W-1810 | FT-019, LT-019, GT-016, GT-020 | ‚úÖ |
| Rust Unit Tests | M0-W-1811 | FT-005, FT-043 | ‚úÖ |
| End-to-End Test | M0-W-1820 | FT-024, FT-041 | ‚úÖ |
| Tokenizer Conformance | M0-W-1821 | LT-018, LT-032, GT-004 | ‚úÖ |
| MXFP4 Numerical Correctness | M0-W-1822 | GT-030, GT-038 | ‚úÖ |
| Large Model Bring-Up | M0-W-1823 | GT-040 | ‚úÖ |
| UTF-8 Streaming Test | M0-W-1824 | GT-028, GT-046 | ‚úÖ |
| OOM Recovery Test | M0-W-1825 | FT-042, GT-045 | ‚úÖ |
| Same-Device Reproducibility | M0-W-1826 | LT-026, LT-036 | ‚úÖ |
| Performance Test Suite | M0-W-1830 | ‚ö†Ô∏è Deferred | M1 |
| Proof Bundle Emission | M0-W-1840 | üî¥ **REMOVED** | Deleted from repo |

**Notes**: 
- All functional tests covered
- Performance tests deferred per hybrid scope
- Proof bundles removed per scope decision

---

### 15. Observability & Logging (80% ‚úÖ)

| Requirement | Spec ID | Covered By | Status |
|-------------|---------|------------|--------|
| Narration-Core Log Events | M0-W-1900 | FT-050 (to be added) | üü¢ |
| Performance Metrics in Logs | M0-W-1901 | ‚ö†Ô∏è Deferred | M1 |
| Sensitive Data Handling | M0-W-1902 | ‚ö†Ô∏è Deferred | M1 |

**Notes**: 
- Narration-core logging covered by FT-050 (to be added)
- All observability requirements will be 100% covered with FT-050

---

## Deferred & Removed Items (Not Gaps)

### ‚ö†Ô∏è Deferred Items (14 items - Performance Bundle)

**Note**: These are intentionally deferred to M1 per hybrid scope decision, NOT gaps.

All performance-related requirements deferred to M1:
- M0-W-1600 through M0-W-1604 (latency targets)
- M0-W-1610, M0-W-1611 (cancellation/disconnect)
- M0-W-1620, M0-W-1630 (startup/shutdown perf)
- M0-W-1830 (performance test suite)
- M0-W-1901, M0-W-1902 (metrics/sensitive data)
- M0-W-1340, M0-W-1350 (optional endpoints)

### üî¥ Removed Items (1 item)

**Note**: This was removed from the repo, NOT a gap.

- M0-W-1840 (Proof Bundle Emission) - Removed from repo per scope decision

---

## Coverage by Team

### Foundation Team (49 stories)

**Coverage**: 100% of Foundation responsibilities (with FT-049 and FT-050 added)

**Key Deliverables**:
- ‚úÖ HTTP server + SSE streaming (FT-001, FT-002, FT-003)
- ‚úÖ FFI layer (FT-006, FT-007, FT-008, FT-009)
- ‚úÖ CUDA context + VRAM enforcement (FT-010, FT-011)
- ‚úÖ Shared kernels (FT-013-020)
- ‚úÖ KV cache (FT-021, FT-022)
- ‚úÖ InferenceAdapter pattern (FT-033, FT-034)
- ‚úÖ Integration tests (FT-023, FT-024, FT-041, FT-042)
- ‚úÖ CI/CD (FT-039)

**Additional Stories Required**: 
- ‚úÖ FT-049: Model loading progress events (1 day) - Week 3-4
- ‚úÖ FT-050: Narration-core logging (1 day) - Week 2-3

**Total**: 49 stories, 87 days (was 47 stories, 85 days)

---

### Llama Team (38 stories)

**Coverage**: 100% of Llama spec responsibilities

**Key Deliverables**:
- ‚úÖ GGUF loader (LT-001-006)
- ‚úÖ GGUF-BPE tokenizer (LT-007-011)
- ‚úÖ Llama kernels (LT-012-017)
- ‚úÖ Qwen integration (LT-022-026)
- ‚úÖ Phi-3 integration (LT-029-032)
- ‚úÖ LlamaInferenceAdapter (LT-033)
- ‚úÖ Reproducibility tests (LT-026, LT-036)

**Spec Coverage Gaps**: None

---

### GPT Team (48 stories)

**Coverage**: 100% of GPT spec responsibilities

**Key Deliverables**:
- ‚úÖ HF tokenizer (GT-001-004)
- ‚úÖ GPT metadata + GGUF v3 (GT-005-007)
- ‚úÖ GPT kernels (GT-008-016)
- ‚úÖ MHA attention (GT-017-020)i
- ‚úÖ GPT basic pipeline (GT-024-027)
- ‚úÖ MXFP4 implementation (GT-029-037) - **20 days of work**
- ‚úÖ GPTInferenceAdapter (GT-039)
- ‚úÖ GPT-OSS-20B end-to-end (GT-040)
- ‚úÖ Large model tests (GT-042-046)

**Spec Coverage Gaps**: None

---

## Acceptance Criteria Coverage

### M0 Success Criteria (from ¬ß15.1)

| Criterion | Covered By | Status |
|-----------|------------|--------|
| 1. Worker binary compiles with `--features cuda` | FT-039 | ‚úÖ |
| 2. Worker loads all 3 models (quantized) | LT-022-026, LT-029-032, GT-024-027, GT-040 | ‚úÖ |
| 3. Worker accepts POST /execute | FT-002 | ‚úÖ |
| 4. Worker generates haiku functionally | LT-025 | ‚úÖ |
| 4b. Worker supports temperature 0.0-2.0 | FT-017 | ‚úÖ |
| 5. Worker streams tokens via SSE (UTF-8 safe) | FT-003, GT-028, GT-046 | ‚úÖ |
| 6. Worker enforces VRAM-only | FT-011 | ‚úÖ |
| 7. VRAM residency verification | FT-014 | ‚úÖ |
| 8. VRAM OOM handling | FT-042, GT-045 | ‚úÖ |
| 9. Worker responds to /health with quant_kind | FT-001, GT-003 | ‚úÖ |
| 10. Worker handles POST /cancel | FT-044 | ‚úÖ |
| 11. Worker shuts down on SIGTERM | Implicit | ‚úÖ |
| 12. All CUDA unit tests pass | FT-019, LT-019, GT-016, GT-020 | ‚úÖ |
| 13. All Rust unit tests pass | FT-005, FT-043 | ‚úÖ |
| 14. Integration test passes (all 3 models) | FT-041, LT-035, GT-042 | ‚úÖ |
| 15. Tokenization works (both backends) | LT-007-011, GT-001-004 | ‚úÖ |
| 16. Quantized execution verified | GT-006, GT-029-037 | ‚úÖ |
| 17. Model load progress events emit | FT-049 (to be added) | ‚úÖ |

**Coverage**: 17/17 criteria covered (100%)

**Note**: With FT-049 and FT-050 added, all M0 acceptance criteria are fully covered

