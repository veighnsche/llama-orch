# Architecture Decision: No Pool Daemon Needed

**Date:** 2025-10-09T17:17:00+02:00  
**Decision By:** User (Vince)  
**Documented By:** TEAM-024  
**Status:** NORMATIVE  
**Impact:** HIGH - Changes M1 milestone

---

## Decision

**pool-managerd (daemon) is NOT needed.**

The pool manager functionality is fully provided by `pool-ctl` CLI (`llorch-pool` binary).

---

## Rationale

### Why Pool Manager Doesn't Need to Be a Daemon

**Key Insight:** Pool management is **control operations**, not **data plane operations**.

**Control operations (SSH-based):**
- Download models
- Spawn workers
- Stop workers
- Check status
- Git operations

**These are all CLI commands, not long-running services!**

### What Needs to Be a Daemon vs CLI

| Component | Type | Why |
|-----------|------|-----|
| **orchestratord** | Daemon | Accepts inference requests 24/7, routes to workers |
| **llorch-candled** (worker) | Daemon | Keeps model in VRAM, accepts inference requests |
| **pool-ctl** (llorch-pool) | CLI | Control operations on-demand via SSH |
| **llorch-ctl** (llorch) | CLI | Remote control operations via SSH |

### The Correct Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ORCHESTRATORD (HTTP Daemon) - M2                                â”‚
â”‚ Binary: orchestratord                                            â”‚
â”‚ Port: 8080                                                       â”‚
â”‚ Purpose: Routes inference requests to workers                    â”‚
â”‚ Runs: 24/7 as daemon                                             â”‚
â”‚ Why daemon: Accepts client requests continuously                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â”œâ”€ HTTP POST /execute (direct to workers)
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ WORKERS (HTTP Daemons) - M0 âœ…                                   â”‚
â”‚ Binary: llorch-candled                                           â”‚
â”‚ Ports: 8001, 8002, 8003, etc.                                    â”‚
â”‚ Purpose: Execute inference, stream tokens                        â”‚
â”‚ Runs: 24/7 as daemon (one per model)                             â”‚
â”‚ Why daemon: Keep model loaded in VRAM                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ POOL MANAGER (CLI Tool) - M0 âœ…                                  â”‚
â”‚ Binary: llorch-pool                                              â”‚
â”‚ Purpose: Local pool operations (models, workers)                 â”‚
â”‚ Runs: On-demand when operator calls it                           â”‚
â”‚ Why CLI: Control operations don't need 24/7 daemon               â”‚
â”‚                                                                   â”‚
â”‚ Commands:                                                        â”‚
â”‚ - llorch-pool models download <model>                            â”‚
â”‚ - llorch-pool worker spawn <backend> --model <model>             â”‚
â”‚ - llorch-pool worker list                                        â”‚
â”‚ - llorch-pool worker stop <id>                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ORCHESTRATOR CLI (CLI Tool) - M0 âœ…                              â”‚
â”‚ Binary: llorch                                                   â”‚
â”‚ Purpose: Remote pool control via SSH                             â”‚
â”‚ Runs: On-demand when operator calls it                           â”‚
â”‚ Why CLI: Control operations don't need 24/7 daemon               â”‚
â”‚                                                                   â”‚
â”‚ Commands:                                                        â”‚
â”‚ - llorch pool models download <model> --host <pool>              â”‚
â”‚ - llorch pool worker spawn <backend> --host <pool> --model <m>   â”‚
â”‚ - llorch infer --worker <host:port> --prompt <text>              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## What This Changes

### âŒ REMOVED: M1 Milestone (pool-managerd daemon)

**Old Plan:**
- M0: Workers + CLIs
- M1: Build pool-managerd daemon (HTTP server)
- M2: Build orchestratord daemon

**New Plan:**
- M0: Workers + CLIs âœ… COMPLETE
- ~~M1: pool-managerd~~ âŒ NOT NEEDED
- M1: Build orchestratord daemon (moved up from M2)

### âœ… SIMPLIFIED: Two-Binary System

**Only 2 daemon binaries needed:**
1. **orchestratord** - Routes inference requests
2. **llorch-candled** - Executes inference

**Plus 2 CLI tools:**
1. **llorch-pool** - Local pool management
2. **llorch** - Remote pool control

---

## Architecture Comparison

### Old (Incorrect) Architecture
```
Client â†’ orchestratord â†’ pool-managerd â†’ worker
         (daemon)        (daemon)         (daemon)
```

### New (Correct) Architecture
```
Client â†’ orchestratord â†’ worker
         (daemon)         (daemon)

Operator â†’ llorch â†’ llorch-pool â†’ spawn worker
           (CLI)    (CLI via SSH)
```

**Key Insight:** Control plane (SSH) and data plane (HTTP) are separate!

---

## Why This Makes Sense

### 1. Pool Manager Has No Long-Running State
- Doesn't need to accept requests 24/7
- Doesn't keep connections open
- Doesn't maintain in-memory state
- All state is in filesystem (catalog.json, worker PIDs)

### 2. Workers Are Already Daemons
- Workers keep model in VRAM
- Workers accept HTTP requests
- Workers are the long-running processes

### 3. Orchestrator Needs to Be a Daemon
- Accepts client requests 24/7
- Maintains queue state
- Routes to workers
- Relays SSE streams

### 4. Pool Operations Are On-Demand
- Download model: Run once, exits
- Spawn worker: Run once, spawns daemon, exits
- Stop worker: Run once, exits
- List workers: Run once, exits

**None of these need a daemon!**

---

## Impact on Specs

### Files That Need Updating

**High Priority (user-facing):**
- [ ] `/ORCHESTRATION_OVERVIEW.md` - Remove pool-managerd references
- [ ] `/QUICK_STATUS.md` - Remove M1 milestone
- [ ] `/bin/.plan/TEAM_025_HANDOFF.md` - Remove pool-managerd tasks
- [ ] `/README.md` - Update architecture section

**Medium Priority (specs):**
- [ ] `/bin/.specs/00_llama-orch.md` - Update Section 6.2 (pool manager)
- [ ] `/bin/.specs/COMPLETE_BINARY_ARCHITECTURE.md` - Remove pool-managerd
- [ ] `/bin/.specs/FINAL_ARCHITECTURE_SSH_CONTROL_HTTP_INFERENCE.md` - Update diagrams

**Low Priority (historical):**
- [ ] Other architecture decision docs (mark as outdated)

---

## New Milestone Plan

### M0: Foundation âœ… COMPLETE
**Deliverables:**
- âœ… llorch-candled (worker daemon)
- âœ… llorch-pool (local pool CLI)
- âœ… llorch (remote control CLI)
- âœ… Model catalog system
- âœ… Worker spawning
- âœ… Token generation

**Status:** DONE by TEAM-022, 023, 024

### CP4: Multi-Model Testing â³ NEXT
**Deliverables:**
- [ ] Download all 4 models
- [ ] Test all backends
- [ ] Document results

**Status:** IN PROGRESS

### M1: Orchestrator Daemon ğŸ”œ AFTER CP4
**Deliverables:**
- [ ] orchestratord binary (HTTP daemon)
- [ ] Client API (`POST /v2/tasks`)
- [ ] Admission control
- [ ] Queue management
- [ ] Scheduling
- [ ] SSE relay

**Status:** NOT STARTED (was M2, moved up)

**Note:** This is now the ONLY daemon left to build!

---

## Updated System Architecture

### Two Daemons (HTTP)
1. **orchestratord** (port 8080) - Routes inference
2. **llorch-candled** (ports 8001+) - Executes inference

### Two CLIs (SSH/Local)
1. **llorch** - Remote control via SSH
2. **llorch-pool** - Local pool operations

### Communication Flow

**Control Plane (Operator):**
```
Operator (human)
    â†“ runs
llorch (CLI)
    â†“ SSH
llorch-pool (CLI on remote machine)
    â†“ spawns
llorch-candled (daemon)
```

**Data Plane (Inference):**
```
Client (SDK)
    â†“ HTTP POST /v2/tasks
orchestratord (daemon)
    â†“ HTTP POST /execute
llorch-candled (daemon)
    â†“ SSE stream
orchestratord (relay)
    â†“ SSE stream
Client
```

**No pool-managerd in either flow!**

---

## Action Items for TEAM-025

### Immediate (Before Starting Work):
1. [ ] Read this decision document
2. [ ] Update TEAM_025_HANDOFF.md (remove pool-managerd)
3. [ ] Update ORCHESTRATION_OVERVIEW.md (remove pool-managerd)
4. [ ] Update QUICK_STATUS.md (remove M1 pool-managerd milestone)

### Then Proceed With:
1. [ ] CP4: Multi-model testing (as planned)
2. [ ] M1: Build orchestratord (not pool-managerd!)

---

## Benefits of This Architecture

### Simpler
- âœ… Only 2 daemons instead of 3
- âœ… Fewer moving parts
- âœ… Easier to understand

### More Maintainable
- âœ… Less code to maintain
- âœ… Fewer HTTP APIs
- âœ… Fewer integration points

### More Reliable
- âœ… Fewer daemons to crash
- âœ… Fewer network calls
- âœ… Simpler failure modes

### More Flexible
- âœ… CLI can be called from scripts
- âœ… CLI can be called via SSH
- âœ… No daemon lifecycle management

---

## Migration Notes

### Code That Doesn't Need to Change
- âœ… llorch-candled (workers) - No changes
- âœ… llorch-pool (pool CLI) - No changes
- âœ… llorch (remote CLI) - No changes

### Code That Never Needs to Be Written
- âŒ pool-managerd HTTP server
- âŒ pool-managerd heartbeat
- âŒ pool-managerd worker lifecycle API
- âŒ pool-managerd GPU discovery API

### Code That Still Needs to Be Written
- â³ orchestratord HTTP server (M1)
- â³ orchestratord admission control
- â³ orchestratord queue management
- â³ orchestratord scheduling
- â³ orchestratord SSE relay

---

## Verification

### Test Current Architecture Works:
```bash
# 1. Spawn worker (CLI)
llorch-pool worker spawn cpu --model qwen-0.5b

# 2. Test inference (CLI)
llorch infer --worker localhost:8001 --prompt "Hello" --max-tokens 20

# 3. Stop worker (CLI)
llorch-pool worker stop-all
```

**Result:** âœ… Everything works without pool-managerd!

### Test Remote Control Works:
```bash
# 1. Remote spawn (SSH + CLI)
llorch pool worker spawn metal --host mac.home.arpa --model qwen-0.5b --gpu 0

# 2. Remote test (CLI to remote worker)
llorch infer --worker mac.home.arpa:8001 --prompt "Hello" --max-tokens 20

# 3. Remote stop (SSH + CLI)
llorch pool worker stop-all --host mac.home.arpa
```

**Result:** âœ… Everything works without pool-managerd!

---

## Conclusion

**pool-managerd is NOT needed.**

The pool manager functionality is fully provided by:
- `llorch-pool` (local CLI)
- `llorch` (remote CLI via SSH)

This simplifies the architecture and removes an entire milestone (M1).

**Next milestone is now building orchestratord (M1, was M2).**

---

**Signed:** TEAM-024  
**Approved By:** User (Vince)  
**Status:** NORMATIVE - Follow this architecture going forward
