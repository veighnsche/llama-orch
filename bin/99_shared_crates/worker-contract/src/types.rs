// TEAM-270: Worker contract types

use serde::{Deserialize, Serialize};

/// Worker information
///
/// Complete state of a worker, sent in heartbeats and returned by /info endpoint.
///
/// # Fields
///
/// - `id`: Unique worker ID (generated by hive at spawn time)
/// - `model_id`: Model being served (e.g., "meta-llama/Llama-2-7b")
/// - `device`: Device worker is using (e.g., "GPU-0", "CPU-0")
/// - `port`: HTTP port worker is listening on
/// - `status`: Current worker status
/// - `implementation`: Worker type (e.g., "llama-cpp", "vllm", "llm-worker-rbee")
/// - `version`: Worker version
///
/// # Example
///
/// ```
/// use worker_contract::{WorkerInfo, WorkerStatus};
///
/// let worker = WorkerInfo {
///     id: "worker-abc123".to_string(),
///     model_id: "meta-llama/Llama-2-7b".to_string(),
///     device: "GPU-0".to_string(),
///     port: 9301,
///     status: WorkerStatus::Ready,
///     implementation: "llm-worker-rbee".to_string(),
///     version: "0.1.0".to_string(),
/// };
/// ```
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
pub struct WorkerInfo {
    /// Unique worker ID (generated by hive)
    pub id: String,

    /// Model being served (e.g., "meta-llama/Llama-2-7b")
    pub model_id: String,

    /// Device (e.g., "GPU-0", "CPU-0")
    pub device: String,

    /// HTTP port worker is listening on
    pub port: u16,

    /// Current worker status
    pub status: WorkerStatus,

    /// Worker implementation type
    ///
    /// Examples:
    /// - "llm-worker-rbee" (Candle-based bespoke worker)
    /// - "llama-cpp-adapter" (llama.cpp wrapper)
    /// - "vllm-adapter" (vLLM wrapper)
    /// - "ollama-adapter" (Ollama wrapper)
    pub implementation: String,

    /// Worker version
    pub version: String,
}

/// Worker status
///
/// Represents the current state of a worker in its lifecycle.
///
/// # States
///
/// - `Starting`: Worker is loading model into memory
/// - `Ready`: Worker is ready to accept inference requests
/// - `Busy`: Worker is currently processing a request
/// - `Stopped`: Worker has been stopped (graceful shutdown)
///
/// # State Transitions
///
/// ```text
/// Starting → Ready → Busy → Ready → ... → Stopped
///    ↓                ↓
///  Stopped         Stopped
/// ```
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
#[serde(rename_all = "lowercase")]
pub enum WorkerStatus {
    /// Worker is loading model into memory
    Starting,

    /// Worker is ready to accept inference requests
    Ready,

    /// Worker is currently processing a request
    Busy,

    /// Worker has been stopped (graceful shutdown)
    Stopped,
}

impl WorkerInfo {
    /// Check if worker is available for inference
    ///
    /// A worker is available if its status is `Ready`.
    pub fn is_available(&self) -> bool {
        self.status == WorkerStatus::Ready
    }

    /// Check if worker is serving a specific model
    pub fn serves_model(&self, model_id: &str) -> bool {
        self.model_id == model_id
    }

    /// Get worker URL
    ///
    /// Returns the base URL for this worker (assumes localhost for now).
    /// Future: Add host field to WorkerInfo for remote workers.
    pub fn url(&self) -> String {
        format!("http://localhost:{}", self.port)
    }
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn test_worker_info_is_available() {
        let mut worker = WorkerInfo {
            id: "test".to_string(),
            model_id: "test-model".to_string(),
            device: "GPU-0".to_string(),
            port: 9301,
            status: WorkerStatus::Ready,
            implementation: "test".to_string(),
            version: "0.1.0".to_string(),
        };

        assert!(worker.is_available());

        worker.status = WorkerStatus::Busy;
        assert!(!worker.is_available());

        worker.status = WorkerStatus::Starting;
        assert!(!worker.is_available());

        worker.status = WorkerStatus::Stopped;
        assert!(!worker.is_available());
    }

    #[test]
    fn test_worker_info_serves_model() {
        let worker = WorkerInfo {
            id: "test".to_string(),
            model_id: "meta-llama/Llama-2-7b".to_string(),
            device: "GPU-0".to_string(),
            port: 9301,
            status: WorkerStatus::Ready,
            implementation: "test".to_string(),
            version: "0.1.0".to_string(),
        };

        assert!(worker.serves_model("meta-llama/Llama-2-7b"));
        assert!(!worker.serves_model("mistralai/Mistral-7B"));
    }

    #[test]
    fn test_worker_info_url() {
        let worker = WorkerInfo {
            id: "test".to_string(),
            model_id: "test-model".to_string(),
            device: "GPU-0".to_string(),
            port: 9301,
            status: WorkerStatus::Ready,
            implementation: "test".to_string(),
            version: "0.1.0".to_string(),
        };

        assert_eq!(worker.url(), "http://localhost:9301");
    }

    #[test]
    fn test_worker_status_serialization() {
        // Test lowercase serialization
        let json = serde_json::to_string(&WorkerStatus::Ready).unwrap();
        assert_eq!(json, "\"ready\"");

        let json = serde_json::to_string(&WorkerStatus::Starting).unwrap();
        assert_eq!(json, "\"starting\"");
    }
}
